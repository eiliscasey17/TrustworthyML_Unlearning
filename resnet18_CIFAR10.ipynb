{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6!pip install torch torchvision\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Download and load the CIFAR10 training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Download and load the CIFAR10 test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define data split percentages\n",
    "train_split_percentage = 0.5\n",
    "importance_split_percentage = 0.1\n",
    "unlearning_split_percentage = 0.3\n",
    "validation_split_percentage = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training subset: 25000\n",
      "Number of samples in importance subset: 5000\n",
      "Number of samples in validation subset: 5000\n",
      "Number of samples in unlearning subset: 15000\n",
      "Number of samples in test dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "total_train_samples = len(train_dataset)\n",
    "\n",
    "train_samples = int(total_train_samples * train_split_percentage)\n",
    "importance_samples = int(total_train_samples * importance_split_percentage)\n",
    "validation_samples = int(total_train_samples * validation_split_percentage)\n",
    "unlearning_samples= total_train_samples - (train_samples + importance_samples + validation_samples)\n",
    "\n",
    "# The remaining samples will form a temporary test set\n",
    "test_samples = len(test_dataset)\n",
    "\n",
    "train_subset, importance_subset, validation_subset, unlearning_subset= torch.utils.data.random_split(\n",
    "    train_dataset, [train_samples, importance_samples, validation_samples, unlearning_samples]\n",
    ")\n",
    "\n",
    "print(f\"Number of samples in training subset: {len(train_subset)}\")\n",
    "print(f\"Number of samples in importance subset: {len(importance_subset)}\")\n",
    "print(f\"Number of samples in validation subset: {len(validation_subset)}\")\n",
    "print(f\"Number of samples in unlearning subset: {len(unlearning_subset)}\")\n",
    "print(f\"Number of samples in test dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformations defined and applied to datasets.\n"
     ]
    }
   ],
   "source": [
    "# Define the mean and standard deviation for CIFAR10 for normalization\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "# Transformations for the training dataset (including augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "])\n",
    "\n",
    "# Transformations for the importance and test datasets (no augmentation)\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "])\n",
    "\n",
    "# Apply the transformations to the respective subsets\n",
    "train_subset.dataset.transform = train_transforms\n",
    "validation_subset.dataset.transform = eval_transforms\n",
    "importance_subset.dataset.transform = eval_transforms\n",
    "test_dataset.transform = eval_transforms\n",
    "\n",
    "print(\"Transformations defined and applied to datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created with batch size: 100\n",
      "Number of batches in training loader: 250\n",
      "Number of batches in importance loader: 50\n",
      "Number of batches in validation loader: 50\n",
      "Number of batches in unlearning loader: 15000\n",
      "Number of batches in test loader: 100\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 100\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "importance_loader = DataLoader(importance_subset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_subset, batch_size=batch_size, shuffle=False)\n",
    "unlearn_loader = DataLoader(unlearning_subset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders created with batch size: {batch_size}\")\n",
    "print(f\"Number of batches in training loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in importance loader: {len(importance_loader)}\")\n",
    "print(f\"Number of batches in validation loader: {len(validation_loader)}\")\n",
    "print(f\"Number of batches in unlearning loader: {len(unlearn_loader)}\")\n",
    "print(f\"Number of batches in test loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Number of model parameters: 11181642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Instantiate the ResNet18 model\n",
    "model = resnet18(pretrained=False)\n",
    "\n",
    "# Modify the final fully connected layer for CIFAR10 (10 classes)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "print(\"Number of model parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function (CrossEntropyLoss) and optimizer (SGD) defined.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Loss function (CrossEntropyLoss) and optimizer (SGD) defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_loss(loss):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(loss)\n",
    "    plt.title(\"Training Loss Over Iterations\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlim([0, len(loss)])\n",
    "    plt.savefig(\"loss_cifar10_resnet.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def display_epochloss(train_loss, val_loss):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlim([0, len(train_loss)-1])\n",
    "    plt.title(\"Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"epochloss_cifar10_resnet.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def display_accuracy(accuracy):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(accuracy)\n",
    "    plt.title(\"Test Accuracy Over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlim([0, len(accuracy)-1])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.savefig(\"accuracy_cifar10_resnet.png\", dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_accuracies = [0 for _ in range(10)]\n",
    "    class_counts = [0 for _ in range(10)]\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_counts[label] += 1\n",
    "                if predicted[i] == label:\n",
    "                    class_accuracies[label] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    for i in range(10):\n",
    "        if class_counts[i] > 0:\n",
    "            class_accuracies[i] = 100 * class_accuracies[i] / class_counts[i]\n",
    "        else:\n",
    "            class_accuracies[i] = 0.0\n",
    "        \n",
    "    model.train()\n",
    "    return accuracy, class_accuracies\n",
    "\n",
    "def compute_val_loss(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    model.train()\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/YAAAIjCAYAAACpnIB8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAASFRJREFUeJzt3QeYXWW5L/A3k0lvhIQ0IBAgSu/SxQKCqHhAhAOXI0WueI70IhqUJmgUEbmo1KtYqOI5IHKPeiBIEUPv0ouEIgkthfRk5j7vmuxh9kwSUqatzO/3PJvZe6211/72nk2e+a/3K93q6+vrAwAAACilmo5uAAAAALDiBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAgBJad91143Of+1xHNwOATkCwB6DDdevWbZlut99++0q/1qxZs+LMM89coXP993//d9GOUaNGRV1d3Uq3pat5++234+tf/3p8+MMfjt69e8fqq68ee+65Z9x8883RWYPzkr6Ln/70pzu6eQDQqPb9uwDQMX7zm99UPf71r38dt9xyS4vtG220UasE+7POOqu4//GPf3y5nnvVVVcVYe8f//hH3HbbbbH77ruvdHu6imeeeSZ22223ePPNN+Pwww+PbbfdNqZOnVp8pnvvvXecfPLJ8cMf/jA6my233DJOOumkFtvz4g4AdBaCPQAd7t/+7d+qHt9zzz1FsG++vSPNnDkzfv/738f48ePjiiuuKAJpZw322dZ+/fpFZzF//vz44he/GO+++27ceeedsf322zfuO+GEE+Lggw+O8847rwj7//qv/9pu7VqwYEHR86Jnz55LPGbNNdfsVN9DAFgcXfEBKIUMYBdccEFssskmRTfu4cOHx1e/+tUiLDb1wAMPFN27hw4dGn369IkxY8bEl7/85WJfVtrXWGON4n5W7SvdqrNr/ge54YYbYvbs2bH//vvHgQceGP/1X/8Vc+bMaXFcbsvzfehDHyraOXLkyPjCF74QL7zwQtV7+T//5//EZpttVhyTbcqu3dn2SjuzXb/85S9bnL95e/N+bnvyySfjf/2v/xWDBw+OXXbZpdj32GOPxWGHHRbrrbde8TojRowoPovsEt/ca6+9FkcccURRie7Vq1fxuf3Hf/xHzJs3L1588cXiNX784x+3eN7f/va3Yt8111yzxM/uP//zP+OJJ56Ib37zm1WhPnXv3j0uvfTSWG211Rrf1+TJk6O2traxZ0Xzyn++3k9/+tPGbVn5P/7442Pttdcu2r7BBhvED37wg6rhEpXPNC8g5Pdo/fXXL47Nz21l5Wfcv3//4nPK715eVMnP8Tvf+U7U19e3uOiSPQAqbc1hCdmm5selK6+8Mrbbbrvo27dv8Xvddddd43/+539aHPfXv/61OC5/x/m7zh4vzS+s5Gc5duzY4pghQ4YU35G8eAbAqkHFHoBSyBCfQTe7cR977LHx0ksvFeHu4Ycfjrvvvjt69OgRU6ZMiT322KMIyhkiMyxmoMsQnnL7xRdfXATWfffdtwjcafPNN//A188K/Sc+8YkiHGewz/P/4Q9/KIJ+xcKFC4vJzCZMmFAcc9xxx8WMGTOKAJXBNsNkygCd72WvvfaK//2//3dROb7rrruKngpZtV4R2Y4Mbt/73vcaQ2K+bobN/Myy3X//+9/jsssuK37ma2XQTa+//noRDDMgH3nkkbHhhhsWQf93v/tdMXQhw+LOO+9cfAZZYW/+uQwYMCD+5V/+ZYlty88pHXLIIYvdP2jQoOL5v/rVr+L5558vgvnHPvax+O1vfxtnnHFG1bHXXXddcTGg8rln+/LYbG9+R0aPHl1cbBg3blz885//LEJ8U9nbIi++5PvMYJ3j/JcmQ/Fbb73VYnuG97xw1PR3nxdndthhhzj33HPjT3/6U9H2/N1mwE/5e/n85z8ff/nLX4rvQHbz//Of/1zMO5Dtb3rhJIN4XujYaaediudnr4J77723GAKS3/GK/LyyN0Se79BDD41f/OIXxYWGbbbZprgIlvI82dMkv2v5e54+fXpxEemhhx6KT33qU0t9/wCURD0AdDJHHXVUJtPGx3fddVfx+Kqrrqo67k9/+lPV9htuuKF4fP/99y/x3G+++WZxzBlnnLHM7Zk8eXJ9bW1t/eWXX964baeddqr/l3/5l6rjfvGLXxTnPv/881uco66urvh52223Fccce+yxSzzmpZdeKo654oorWhzTvO15P7cddNBBLY6dNWtWi23XXHNNcfydd97ZuO2QQw6pr6mpWeznVmnTpZdeWjzvqaeeatw3b968+qFDh9Yfeuih9Uuz5ZZb1g8aNGipx+Rnlue/6aabql7v8ccfrzpu4403rv/kJz/Z+Pjss8+u79evX/2zzz5bddw3v/nN+u7du9dPmjSp6jMdOHBg/ZQpU+qXxTrrrFM8Z3G38ePHNx6X7z+3HXPMMVWf22c/+9n6nj17Ft+5dOONNxbHnXPOOVWv88UvfrG+W7du9c8//3zx+Lnnnit+H/vuu2/9woULF/v7aNq+pr/LfG+9evWqP+mkkxq3bbHFFkVbAFh16YoPQKd3/fXXF1XdrC5m9bRyy6pkdoHOCmjKCn3KWdaz0tparr322qipqYn99tuvcdtBBx0Uf/zjH6uGAmSX8xwCcMwxx7Q4R6U6nsfk/eaV6KbHrIh///d/b7GtaUU5q9T5mWVFOWW1NmV39RtvvLGYwG5xvQUqbTrggAOKbtxZoa/IanOe84PGoGevhazqL01lf1aTU/amyO74WaGvyF4P2XW+6Tj8/G589KMfLbqqN/1u5PwHWUXPMf1N5e+wMhxjWeTQgez50PyWv//mjj766KrPLR/nUIZbb721cVWF7G2QPU6ayq75ec0mv08pfx/5ezn99NOL793SviMbb7xx8f4r8r1l9/7sqVGR/19kL43nnntumd83AOUi2APQ6WUgmTZtWgwbNqwILk1v7733XtEFP2WX7Axu2Y05A3Z2786u13Pnzl2p16+Mdc6x6dn1OW9bbbVVEdoyWFbkOPoMVRlIlySPyfHXH9QFfHnlmPjm3nnnnWI4QM5HkCE/P6/Kcfl5ppylPsP0pptuutTzZzjM8H/11Vc3bsuQn5PLffKTn/zA0J7hfmkq+ysBP39/OYt+dsevyJCfn21lCEXlu5Hd3pt/LyoTG1a+G0v7nJYm25Hnan5bZ511qo7LAJ5DFprKeRZSDgdJL7/8cvG7b36Ro7LaQ+6vfEfyfBnaP0gOPWguL3I0veCUXflzmEW2J+d1yK7/Of8CAKsOY+wB6PSyepmhvmm1uKlKBTarmTkuPMeP57jurCjnZHE/+tGPim1Z3V9eGRzvv//+4n6OYW8u25TjtVvTkir3WYFekqbV+Yqssud48wxyOZ47339+ljkWvOnEcssqx8jnhYw8ZwbEm266Kb72ta+1qCo3l8H1kUceiUmTJi02iKZK0GwaZnOegpwfIJ+b7c+Qn2E/w3ZFvo/syXHKKacs9ryVcL20z6nMsgfA4jSdjC8n3cuLBbmqQ06+93//7/8txvNfcsklxbh7AMpPsAeg08tJ57I7c07gtizBLLub5+273/1uUWHO5dSyO32GmOXt7p7BPSfm+81vftMiROVs5BdeeGFjYM125gRnOQwgn7Ok95IXHLKavqSqfVZcU1ZZm6pUdJdFVmxzEr/svZBduiuad8fOiyIDBw4surl/kLwgkMfnZ5Jd1HPiui996Usf+LycUDBnzc/Z2r/97W+32J89BjJ05qR9OXFexT777FNMiFfpjv/ss88Wk+I1/zyz10ZHLz2YFxiy+3vTCwnZ3rTuuusWP7PKn9/j5kMTnn766cb9lfeU58thB3lBozXkdy0vkuQtP68M+zmpnmAPsGrQFR+ATi8rz1mtPvvss1vsy1nHKwE4w2zzZcMqwajSHT+XDltcaF6SDLE5hjnHdefs401vWQlPlaXechhAju9uuhRbRaVdeUzeX9xSbpVjMmhnVbr5+PCLLroollXlIkTzz6P5LPFZbc8AnT0cKsvtLa5NKbvB59jyrJznrP5ZtV+WFQXys8pK/Pe///0Wr5EBNlcpyN9d83kHsvt/Lh+Xr5cXZnJm+Gxr8+/GxIkTi4slzeXvOL8f7aXp7z0/t3ycF3iyl0H6zGc+U3yPm38/snqeF5xylYSU7zF/L9mFvnnPisUti/dBmi9vmD038gLKyg5RAaDzULEHoNPLsfNZuc0lu7Jbdi73lYEpq8/ZNTzXhM/wmMulZfjNpeyy6pmV0csvv7wIyhmqUlb8M2RmFTirq1nJzPHlixtjntX3HE/fdFK0pnJ8+dZbb12E/2984xtFV/WsSp944olx3333FRcEct3yrNJml/Uc859L5mWVOyv92f5Kt/hc7i73VV4rK6kZhPNnTmqXIb9SAV4W+Z6zKptLr2UPgmxrdsPOZQKbyyXycl9+zjmsILvO51Jx+dlmr4TKpIQp32O2PScszLXil0UG8hwikQE310/PqnG+pwze2aMiJ/LLCeSy631zeUElJ+fL32uG/KZtSXlxJYcEZK+AyjJv+Zk//vjjxWvm+PamXfeXVy5Dl3MsNJfhuOlFhpxYMMf655Jz2ZshJ8L7f//v/8Wpp57aOFQk5yjI3/G3vvWtol1bbLFF8blnb4Xjjz++cTnEDN15TF7Iyu9QzimQS/PlkJAco5//HyyP/L5//OMfLz6b/L7nxZX8bJb0vQaghDp6Wn4A+KDl7iouu+yy+m222aa+T58+9QMGDKjfbLPN6k855ZT6119/vdj/0EMPFcu+jR49uljya9iwYfWf+9zn6h944IGq8/ztb38rzpNLkS1t6btcviz3v/DCC0ts65lnnlkc8+ijjzYuMfetb32rfsyYMfU9evSoHzFiRLGcWdNzLFiwoP6HP/xh/YYbbli0YY011qjfa6+96h988MHGY/I8RxxxRLFMXL7XAw44oFjKbEnL3VWWVGvq1VdfLZZMW2211Yrz7L///sVntbj3/PLLLxfL3mVb8rNbb731it/D3LlzW5x3k002KZZjy/Mvj2z/iSeeWL/BBhsUr5Ht2n333RuXuFuc6dOnF7/vbPOVV1652GNmzJhRP27cuOK8+XnmEny5HOF5551XLMnXdLm7/NyX1dKWu8t9TZe7yyX38ne8xx571Pft27d++PDhxWfcfLm6bOsJJ5xQP2rUqOL7MXbs2KJNTZexa7p84lZbbVV8VoMHD67/2Mc+Vn/LLbdUtW9xy9jlcXmryOX1tttuu+Lzzs8yv3ff/e53Gz8bAMqvW/6noy8uAADlkSsCZOU3x/ATRU+BrIDn2HUA6AjG2AMAyyy7cedwiOySDwB0DsbYAwAfKGfNf/DBB4ulA0eOHFmMfQcAOgcVewDgA2VX85z0Lifiy1UAcrI4AKBz6NBgnzP85gyxOcNrLvNy4403Vu3P4f+59m5WBnIW41yjtvn6u7kOcK5PnLP/5ky5RxxxhDFuANDKcs3znL3/qaeeKmbP53259J+/PQDossE+l6PJpV5+9rOfLXZ/LtGTS+pccsklxZJD/fr1K5a6mTNnTuMxGer//ve/xy233BI333xzcbEgl+oBAACArqDTzIqfFfsbbrihcU3YbFZW8nNd25NPPrnYNm3atBg+fHhxZTzXus2qQa7Nmuu65nq4KdeQzbWKX3311eL5AAAAsCrrtJPnvfTSS/HGG28U3e8rBg0aFNtvv31MnDixCPb5M7vfV0J9yuNramqKCv++++672HPPnTu3uFVk18Ls0j9kyJDiAgMAAAC0pSxmz5gxoyhIZ4ZdJYN9hvqUFfqm8nFlX/4cNmxY1f7a2tpibd3KMYszfvz4OOuss9qk3QAAALCsXnnllVhrrbVilQz2bWncuHFx4oknNj7OLv6jR48uPtCchA8AAADa0vTp02PttdeOAQMGrPS5Om2wHzFiRPFz8uTJxaz4Ffl4yy23bDxmypQpVc9bsGBB0a2+8vzF6dWrV3FrLkO9YA8AAEB7aY3h4J12HfsxY8YU4XzChAlVVzRy7PyOO+5YPM6fU6dOjQcffLDxmNtuu60YM59j8QEAAGBV16EV+1zz9fnnn6+aMO+RRx4pxshn1/jjjz8+zjnnnBg7dmwR9E877bRiYoHKzPkbbbRRfPrTn46vfOUrxZJ48+fPj6OPPrqYWM+M+AAAAHQFHRrsH3jggfjEJz7R+Lgy7v3QQw8tlrQ75ZRTirXuc136rMzvsssuxXJ2vXv3bnzOVVddVYT53XbbrZhJcL/99osLL7ywQ94PAAAAdNl17DtSdvHPpfRyEj1j7AEAAChTDu20Y+wBAACADybYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJSbYAwAAQIkJ9gAAAFBigj0AAACUmGAPAAAAJdapg/3ChQvjtNNOizFjxkSfPn1i/fXXj7PPPjvq6+sbj8n7p59+eowcObI4Zvfdd4/nnnuuQ9sNAAAA7aVTB/sf/OAHcfHFF8dPf/rTeOqpp4rH5557bvzkJz9pPCYfX3jhhXHJJZfEvffeG/369Ys999wz5syZ06FtBwAAgPbQrb5p+buT+dznPhfDhw+Pn//8543b9ttvv6Iyf+WVVxbV+lGjRsVJJ50UJ598crF/2rRpxXN++ctfxoEHHrhMrzN9+vQYNGhQ8dyBAwe22fsBAACA1s6hnbpiv9NOO8WECRPi2WefLR4/+uij8de//jX22muv4vFLL70Ub7zxRtH9viI/mO233z4mTpy4xPPOnTu3+BCb3gAAAKCMaqMT++Y3v1mE7g033DC6d+9ejLn/7ne/GwcffHCxP0N9ygp9U/m4sm9xxo8fH2eddVYbtx4AAADaXqeu2P/2t7+Nq666Kq6++up46KGH4le/+lWcd955xc+VMW7cuKK7Q+X2yiuvtFqbAQAAoD116or917/+9aJqXxkrv9lmm8XLL79cVNwPPfTQGDFiRLF98uTJxaz4Ffl4yy23XOJ5e/XqVdwAAACg7Dp1xX7WrFlRU1PdxOySX1dXV9zPZfAy3Oc4/Irsup+z4++4447t3l4AAABob526Yr/33nsXY+pHjx4dm2yySTz88MNx/vnnx5e//OVif7du3eL444+Pc845J8aOHVsE/Vz3PmfK32effTq6+QAAANC1g32uV59B/Wtf+1pMmTKlCOxf/epX4/TTT2885pRTTomZM2fGkUceGVOnTo1ddtkl/vSnP0Xv3r07tO0AAAAQXX0d+/ZiHXsAAADaU5dZxx4AAABYOsEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAoMcEeAAAASkywBwAAgBIT7AEAAKDEBHsAAAAosdqObgAAAAB0FfX19TFvYV1MmzW/1c4p2AMAAMAi8xbUxez5C2PO/IUxa97CmJ23po/z/ry8vyBmz284dnZxP3/WLTpu0ePc32Rf5X5dfUTd3FnRWgR7AAAASmHBwkqQbgjYsxeF7TnNHy86pvF+i1D+flhvfo4FmbpLRrAHAABgpS2sq28M3U2r2w0hfEFDxXpRkC4q15XHi61uV4fySpCfv7D9QndNt4i+PWujd4/u0bdn9+jTo3v07tk9+vboHn0WPV7iz+bbmmzPc+V55s+eGUMvaJ22CvYAAJ34j+SiO+e8hTFzUbfP/CM3olt0r+kWtTUNPyu3fFzTrVvUdl+0Le/X1ET3fNytyTH51yq08RjirHouXHRrer/hcV3U1UXxs9iWxy9ctL++4Wd9ffX5qs7f4vWaPW5+RP2KP7fl/pbvdWn7q1/7A869kq/V/PlNj/jgc0djiG4eyqu6oDfpnl513PyFRRf29tKtW7wfkns0CcyLgnTz7ZVQ3vI5tdGnZ82i8F5bFcp7dO8W3fKF2sj0ea03l71gDwCwEvIP7Tnz64rQnX/gNtyqw3jl/uxmxzQ/vvm+uW30R3L+ndo86DdcJKiJ7jXRcDFgKRcMqh/XRPc8X01N1YWG6vNWb6+8zmKf0+zCRLG9+6Lti9q1bK9T/RpNj2nxnEWvsyJ/wOfvP3vtLk9grX5c1/C4sq+uPuoWG4Qbjl1Yl69V1yI0Vz2nyevUFQG7oS3L9jpLaf8S309d8Rk0PifPXb6ezLSy5a1if2AFvFko71Vb06ahu2wEewCgS5i/sC5mzV0Ys+YvCtRzFwXo+e/fz4rTzLnvB/CmYbxhX9P7i/bNX7iYKlnrygJ7v6Kq1PDHbVpSqGsazJYUrrK9CxZVVOe2bdNLpepiQpPwnz8zwDetPDf93Fk+PRov1DS9GFN9kafhQkv185pHuOahruX+5s9vdvwyZMLlfo3lfM0WTVju97SS7W12RK8eNY0hemmV8KL63bTC3azinaFbz6D2JdgDAJ1GBqUiNFdVsFtWuYsK+KKQXrmf4zcXf9yCdhuX2btHTWMAzz9+84/cvs3u577qY1rua37cilammofRosK6cFEorXSVLh7XNT5+v8rbsmJc16xy3FgJXkqVua6xwlvXUO1d9JpNK8fNHzec6/3q7+Kr182qzJWKcfNzL0cQL47NDso52qEVZK5ZXO+HFr0hltSToUWPhcU9Xkrvh+a9Ero3eU72sui+9Nep7v2w+Pew1B4TVa/Z8DrCHrQNwR4AWG4ZgN6bu6C4zVpUxV6mML6E7ugN+3L8eF27VAuzotSv17IF8GUN43nOzhZa8mJAhrXahiI/TbrOt+hyvpiLBk0vTNQUQxTerywvKTQ3Dca6CQPtRbAHgC7WHT0r2DPmNITy4jZnQUyfM7/x/ntN91ceF9vmNz7OMN6WMg81zDpcG/16vd8VtAjji+737VVbHNN4f1H30MbA3jy892i437O29SYronwybDfMCVC52uGqB1B+gj0AlEDONFwJ2jPmvh+wKyG8IYg3bM8Q/l6L4N6wv7Ur4hmS+zWreLesbi9DNbxJYM/7JkUCgGUn2ANAG8qlgBZbCW8SwottVfurq+cZylt7CaEcCz6gd48Y0Ks2+veujf75c9H9yrbcn9sGtNjfo/E5qt8A0PEEewBYzBjcXGas6J7epEt680p4Q6X8/RC+uEr5vJxhrBVlRbsxbFeCeZNwXgnhRShvEtIrwTz3Z0W8R862BQCsEgR7AFapQJ6zn7eshM9fwpjxfNwQzJuPOW/tJayqKt7NQnj/Xi1DeO5r2P9+dTxvOSEXAEBTgj0AHbqmeM6EXpkZvVi+bN6CYub0nGm9MoN608eNs603Pvf9tcVzX2vm8RziXYTsqsDdJIS3qJQv2tcspPfrWdvpZksHAFYdgj0AS5XrPs+av7BqSbOmYbqyRnhjKG8SzotQ3iysN5xrYat3UW8qq9pNu573/8Ax49XBvbI/u72bwA0A6OwEe4BVbFx4VejOEL6osl1ZJ7x5pbtxe1Xl+/2QnqG9LfXsXhN9e70/Q3plCbNc4ixnUG/8WcyeXv24ssRZMZP6oudnMM+J4QRyAKCrEOwBOqobepPw/H6IXrCEyveyhfVWHhZeJXuS98vwvChYN4bppqF8UdiuLH9WCeGVZc6ah/XcbhI3AICVI9gDrKRchmzy9Dnx+tTZ8c9pcxbdZscb0+YUE7K16Mbext3QU1as+zUL3ZV1wvNn5XElnDesI16phLcM69YVBwDovAR7gA+orGdoz5D+egb2xvDe8PP1qXPirffmrvD5a2u6FaF5sd3Km1S+Gyrh1SG9UgWvPK6cI8O7mdMBALoOwR7oshbW1ceUGQ3h/I1FYT3vV0J7/nxzxtxl6t7es7YmRg7qXdxGDeoTI1frHSMG9o6BfXpUVcCbd03P5wEAwMoQ7IFVdib3rKQ3r7JXHmeQnzxjbhHuP0iP7t1iRBHa+ywK731i1GpNH/eO1fv11E0dAIAOIdgDpQztb8+ct6h7/OyG4D49A/v7VffsPr9gGUJ7dlnPynoR0Fd7P6hXwnsG+qH9elmDHACATkuwBzrdkm3vzppfTETX2D2+qure0G1+WSafyyw+fGBDOC+6xzcL76NW6xND+/cyHh0AgFIT7IF2De3TZy9oqLJXxrFPrVTd58QbWXWfNjvmzP/g0J693tfo36sI6qMGNQnvq71fcR82oFfUWkoNAIBVnGAPtJoZc+Yvmim+ybJvi+5neM9Key75tiyG9u/ZOIY9K+sNY9wb7ufPYQN6m3gOAAAEe2BZzZy7oEWVvfkScO/NXbBM58qJ5pqOZc8qe1bbK1X34YN6Ra/a7m3+ngAAYFUg2AMxe97CJku8NQT1IrBXwvvU2TF9zrKF9kF9elRV2Uc1Ce+VCnzvHkI7AAC0FsEeuoC5CxbG469Oi0nvzGpc9q2h6p4T0c0uJqtbFgN617ZY7q352PZcmx0AAGg//gKHVdTLb8+MO599M+549s342wtvf+DY9n49uy9hubeGyelyX/9e/skAAIDOxl/psIqYNW9B3PPi23HHMw1h/h9vz6ran8u6fXhE/8bu8O93j2+4P7B3bXTLqeYBAIBSEeyhxEvHPTv5vcaq/H0vvVO1tnttTbfYdt3B8bEPDYtdPzQ0NhoxMGqs1w4AAKscwR5KZNrs+XH38281VuVz3fem1hrcJz72oTWK247rD4kBvXt0WFsBAID2IdhDJ1ZXVx+PvzatCPFZmX/4lamxsK6+cX+v2poiwGeQ3/VDa8R6Q/vpTg8AAF2MYA+dzJsz5sZdzzVU5O967q14Z+a8qv0bDOvfWJXfbszqlo4DAIAuTrCHDjZ/YV089PK7DVX5596MJ16bXrV/QK/a2HmDofGxDzdU5ddcrU+HtRUAAOh8BHvoAK++OyvufPatuOPZKXH382/He3MXVO3fdM2Bi6ryw2Kr0atFj+41HdZWAACgcxPsoR3Mmb8w7n3pnWLSu6zKPz/lvar9q/frGbuObajK77LBGrHGgF4d1lYAAKBcBHtoo6XoXnxrZuPs9bm+/NwF7y9Fl6vObT06l6Jbowjzm44aZCk6AABghQj20EpmzJkff3vh7cYZ7F99d3bV/pGDejfOXr/z+kNjUF9L0QEAACtPsIeVqMo/+c/pRZDPyvyDL78bC5osRdeze00xa32lKj92WH9L0QEAAF0v2L/22mvxjW98I/74xz/GrFmzYoMNNogrrrgitt1228ZwdcYZZ8Tll18eU6dOjZ133jkuvvjiGDt2bEc3nVVQLj3XdCm6XJquqTFD+y2qyg+NHdYbEn17dvr/xQAAgJLr1Knj3XffLYL6Jz7xiSLYr7HGGvHcc8/F4MGDG48599xz48ILL4xf/epXMWbMmDjttNNizz33jCeffDJ69+7doe2n/BYsrItHX53WUJV/9s147NWpUf9+UT769uweO60/pLGL/TpD+nVkcwEAgC6oW32WvDupb37zm3H33XfHXXfdtdj92fRRo0bFSSedFCeffHKxbdq0aTF8+PD45S9/GQceeOAyvc706dNj0KBBxXMHDhzYqu+B8nlj2pxijHwG+b8+/1ZMmz2/av+GIwYUXes/NnaN2GbdwdGrtnuHtRUAACin1syhnbpif9NNNxXV9/333z/uuOOOWHPNNeNrX/tafOUrXyn2v/TSS/HGG2/E7rvv3vic/GC23377mDhx4hKD/dy5c4tb0w+UrmvugoXxwD/ebQzzT78xo2r/oD49Ypdcii6r8mPXiBGD9AQBAAA6j04d7F988cVivPyJJ54Yp556atx///1x7LHHRs+ePePQQw8tQn3KCn1T+biyb3HGjx8fZ511Vpu3n87r5bdnNk56lzPZz56/sHFfzm+3xVqrNXav32KtQVHbvaZD2wsAAFDKYF9XV1dMkve9732veLzVVlvFE088EZdcckkR7FfUuHHjiosFTSv2a6+9dqu0mc5p1rwFMfGFtxur8v94e1bV/qH9ezXOXv/RDYbG4H49O6ytAAAAbRbsM2hnl/gc8/7yyy8Xs9TnhHYZuLM7fGuH45EjR8bGG29ctW2jjTaK//zP/yzujxgxovg5efLk4tiKfLzlllsu8by9evUqbqy6cv6FZye/F3c8O6UI8ve/9G7MW1jXuL+2pltsu+7g+NiHhhUz2G80YmDU1FiKDgAAWEWD/ezZs+NHP/pR0S3+nXfeKUJzTlrXp0+feP755+PGG28sxr3vsccecfrpp8cOO+zQKo3LGfGfeeaZqm3PPvtsrLPOOsX9nAU/w/2ECRMag3xW3++99974j//4j1ZpA+Uxbdb8uPuFt4ru9Rnm35g+p2r/WoP7NFTlP7RG7Lj+kBjQu0eHtRUAAKBdg/2HPvSh2HHHHYu14j/1qU9Fjx4tA1FW8K+++upiwrpvfetbjRPcrYwTTjghdtppp6Ir/gEHHBD33XdfXHbZZcUtdevWLY4//vg455xzinXrK8vd5UWHffbZZ6Vfn86trq4+Hn/t/aXoHp70btQ1WeOhV21NEeArY+XXG9qv+M4AAAB0ueXunnrqqaIL/LKYP39+TJo0KdZff/3WaF/cfPPNxZj4XL8+g3uOjW960SCbf8YZZxRhf+rUqbHLLrvERRddVFyMWFaWuyuPN2fMjbueawjydz33Vrwzc17V/g2G9W+sym83ZvXo3cNSdAAAQOfTmjm0U69j314E+85r/sK6eOjldxur8n9/vXppwgG9amPnDYYWk95lVX7N1fp0WFsBAABKtY79ggUL4tJLL43bb789Fi5cWIyHP+qoo6J3b2t8s3JefXdW3PnsW8XEd3c//3a8N3dB1f5N1xy4qCo/LLYavVr0sBQdAADQha1wsM/15HMiuy984QtF9/tf//rX8cADD8Q111zTui1klTdn/sK496V3Fk16NyVeeHNm1f7V+/WMXcc2VOV32WCNWGOAFQ0AAACWO9jfcMMNse+++zY+/p//+Z9ixvru3RvGMO+5556tNhs+q7YFC+vixbdmFmPkc135e158O+YueH8pulx1buvRgxvXld901CBL0QEAAKzsGPu99967CPE5MV3OOp+z1Od4gP3226+o2OeM+bks3i233BJlY4x925g2e368+OZ78eKbM+OFN99bdJsZL789M+YvrP7ajRzUu3H2+p3XHxqD+lqKDgAAWHVN74gx9n/4wx/iuuuui49//ONxzDHHFLPQn3322cXSdpUx9meeeeZKNYZyLjn32tTZjaE9g3zlfs5gvyS9e9TEtuus3liVHzusv6XoAAAA2mNW/FxS7pRTTolHH300Lrnkkthqq62i7FTsP9iseQuaVN4bfr64KMg37Ubf3LABvWL9NfrH+sP6FT/Xy/tr9ItRg/roXg8AAHRZ0ztyVvzVVlutqNbfeeedccghh8SnP/3ponJvNvzyy2s8k6fPraq6Fz+nvBevT5uzxOf16N4t1h3SryrA523MGv1iYG9d6gEAANrSMgf7SZMmxcknnxxPPfVUbL755nHeeefFgw8+GN/97ndjiy22iAsuuCD22muvNm0srTcL/ctvz1pUda8O8DPnLVzi83J2+qy2rze0OsCvNbhP1FpyDgAAoHN3xc+x9SNGjIjDDjss/vznP8cLL7wQN910U7Evw/5Xv/rVYv9vf/vbKJtVsSt+/lrfmTmvKrTnTPR5/5V3ZkXdEn7r3Wu6xejV+xYBvqHr/Ptd6DPYAwAAUNKu+LlGfY6rX3/99Yul7caMGdO4b6ONNiq65mcXfdrX/IV1RVBvGuCLSvxbM2PqrPlLfN6AXrWx3rCG8e6VynveHz2kb/SqbVjCEAAAgM5vmYP9NttsE6effnoceuihceutt8Zmm23W4pgjjzyytdtHs6Xjmgf47FK/YAnl95xkfs3V+jROWNcY4If1izX69zILPQAAQFcK9r/+9a/jpJNOihNOOCG23HLLuPTSS9u2ZV3Qwrr6eH3q7Hi+adf5IsDPjLfeW/LScX16dG/SZb7J5HVD+0WfnqrvAAAAq7JlDvbrrLNO/O53v2vb1nQRM+cuiJcWjXcvgvuiAJ/blrZ03PCBi5aOW1SBLyrxw/rHyIG9LR0HAADQRS1TsJ85c2b069dvmU+6vMevykvHNSwbV+k637Du+9KWjuvZvSbWHdq3qtt8pfo+wNJxAAAArEiw32CDDeK4444rxtePHDlyiUE2x96ff/75seuuu8a4ceOiqywd94+3M7BXus2/H+CXtnTckGLpuCZd5xcF+LUG9y1mpgcAAIBWC/a33357nHrqqXHmmWcWa9Zvu+22MWrUqOjdu3e8++678eSTT8bEiROjtra2CPS59N2qJC9avJ1LxzWpulcC/CvvzoolLRiYAX2d1fsu6jLfL9ZftP57rgM/2NJxAAAAtOc69mnSpElx/fXXx1133RUvv/xyzJ49O4YOHRpbbbVVsQTeXnvtFd27dy/t+oFvvfNuTF1Q2xjgi2XjFgX4nJV+SQb0rm3Rdb5YOm71ftGztqZd3wsAAABdax375Qr2q/oHOubE66OuR5/FHpMrw601uE9Rba8O8P1jaP+elo4DAACgQ4L9Ms+K3xXkevD9enRvDO1FiG8yeV3vHuXrjQAAAMCqTbBv4pYTdo2xaw2zdBwAAAClYQB4EyNX6yPUAwAAUCqCPQAAAJSYYA8AAABdKdivu+668Z3vfKdY+g4AAAAoWbA//vjj47/+679ivfXWi0996lNx7bXXxty5c9umdQAAAEDrB/tHHnkk7rvvvthoo43imGOOiZEjR8bRRx8dDz300PKeDgAAAFgJ3err6+tX5gTz58+Piy66KL7xjW8U9zfbbLM49thj4/DDD49u3coxw/z06dNj0KBBMW3atBg4cGBHNwcAAIBV3PRWzKErvI59hvgbbrghrrjiirjllltihx12iCOOOCJeffXVOPXUU+PWW2+Nq6++eqUaBwAAALRysM/u9hnmr7nmmqipqYlDDjkkfvzjH8eGG27YeMy+++4bH/nIR5b31AAAAEBbB/sM7Dlp3sUXXxz77LNP9OjRo8UxY8aMiQMPPHB5Tw0AAAC0dbB/8cUXY5111lnqMf369Suq+gAAAEAnmxV/ypQpce+997bYntseeOCB1moXAAAA0BbB/qijjopXXnmlxfbXXnut2AcAAAB04mD/5JNPxtZbb91i+1ZbbVXsAwAAADpxsO/Vq1dMnjy5xfZ//vOfUVu7wqvnAQAAAO0R7PfYY48YN25cTJs2rXHb1KlTi7Xrc7Z8AAAAoP0sd4n9vPPOi1133bWYGT+736dHHnkkhg8fHr/5zW/aoo0AAABAawX7NddcMx577LG46qqr4tFHH40+ffrE4YcfHgcddNBi17QHAAAA2s4KDYrPdeqPPPLI1m8NAAAAsFxWeLa7nAF/0qRJMW/evKrtn//851f0lAAAAEBbB/sXX3wx9t1333j88cejW7duUV9fX2zP+2nhwoXLe0oAAACgvWbFP+6442LMmDExZcqU6Nu3b/z973+PO++8M7bddtu4/fbbV7QdAAAAQHtU7CdOnBi33XZbDB06NGpqaorbLrvsEuPHj49jjz02Hn744RVpBwAAANAeFfvsaj9gwIDifob7119/vbify98988wzK9IGAAAAoL0q9ptuummxzF12x99+++3j3HPPjZ49e8Zll10W66233oq2AwAAAGiPYP/tb387Zs6cWdz/zne+E5/73Ofiox/9aAwZMiSuu+66FWkDAAAAsIK61VemtV8J77zzTgwePLhxZvyymT59egwaNCimTZsWAwcO7OjmAAAAsIqb3oo5dLnG2M+fPz9qa2vjiSeeqNq++uqrlzbUAwAAQJktV7Dv0aNHjB492lr1AAAAUNZZ8b/1rW/FqaeeWnS/BwAAAEo2ed5Pf/rTeP7552PUqFHFEnf9+vWr2v/QQw+1ZvsAAACA1gz2++yzz/I+BQAAAOjMs+KXnVnxAQAA6BKz4gMAAAAl74pfU1Oz1KXtzJgPAAAAnTjY33DDDS3Wtn/44YfjV7/6VZx11lmt2TYAAACgvcbYX3311XHdddfF73//+ygbY+wBAACIrj7GfocddogJEya01ukAAACA9gr2s2fPjgsvvDDWXHPN1jgdAAAA0FZj7AcPHlw1eV725J8xY0b07ds3rrzyyuU9HQAAANCewf7HP/5xVbDPWfLXWGON2H777YvQDwAAAHTiYH/YYYe1TUsAAACAth9jf8UVV8T111/fYntuyyXvAAAAgE4c7MePHx9Dhw5tsX3YsGHxve99r7XaBQAAALRFsJ80aVKMGTOmxfZ11lmn2AcAAAB04mCflfnHHnusxfZHH300hgwZ0lrtAgAAANoi2B900EFx7LHHxl/+8pdYuHBhcbvtttviuOOOiwMPPHB5TwcAAAC056z4Z599dvzjH/+I3XbbLWprG55eV1cXhxxyiDH2AAAA0M661dfX16/IE5977rl45JFHok+fPrHZZpsVY+zLavr06TFo0KCYNm1aDBw4sKObAwAAwCpueivm0OWu2FeMHTu2uAEAAAAlGmO/3377xQ9+8IMW288999zYf//9W6tdAAAAQFsE+zvvvDM+85nPtNi+1157FfsAAACAThzs33vvvejZs2eL7T169CjGCAAAAACdONjnRHnXXXddi+3XXnttbLzxxq3VLgAAAKAtJs877bTT4gtf+EK88MIL8clPfrLYNmHChLjmmmvi+uuvX97TAQAAAO0Z7Pfee++48cYbizXrf/e73xXL3W2++eZx6623xsc+9rGVaQsAAADQXuvYL84TTzwRm266aZSNdewBAAAoaw5d7jH2zc2YMSMuu+yy2G677WKLLbZY2dMBAAAA7RHsc2m7Qw45JEaOHBnnnXdeMd7+nnvuWdHTAQAAAG09xv6NN96IX/7yl/Hzn/+86DZwwAEHxNy5c4sx92bEBwAAgE5csc9J8z784Q/HY489FhdccEG8/vrr8ZOf/KRtWwcAAAC0TrD/4x//GEcccUScddZZ8dnPfja6d+8e7e373/9+dOvWLY4//vjGbXPmzImjjjoqhgwZEv3794/99tsvJk+e3O5tAwAAgE4d7P/6178WE+Vts802sf3228dPf/rTeOutt6K93H///XHppZcWS+s1dcIJJ8Qf/vCHuP766+OOO+4oehJ84QtfaLd2AQAAQCmC/Q477BCXX355/POf/4yvfvWrce2118aoUaOirq4ubrnlliL0t5X33nsvDj744OL1Bw8e3Lg9lwXI8f7nn39+MXlfXnS44oor4m9/+5uJ/AAAAOgSlntW/H79+sWXv/zlooL/+OOPx0knnVR0kR82bFh8/vOfb5NGZlf77P6/++67V21/8MEHY/78+VXbN9xwwxg9enRMnDhxiefLCf9y8r+mNwAAACijlVrHPifTO/fcc+PVV1+Na665JtpC9gx46KGHYvz48Yudpb9nz56x2mqrVW0fPnx4sW9J8lyDBg1qvK299tpt0nYAAADo1MG+IifS22effeKmm26K1vTKK6/EcccdF1dddVX07t271c47bty4oht/5ZavAwAAAF022LeV7Go/ZcqU2HrrraO2tra45QR5F154YXE/K/Pz5s2LqVOnVj0vZ8UfMWLEEs/bq1evGDhwYNUNAAAAyqg2OrHddtutGMff1OGHH16Mo//GN75RdKHv0aNHTJgwoVjmLj3zzDMxadKk2HHHHTuo1QAAANB+OnWwHzBgQGy66aYtJu/LNesr24844og48cQTY/XVVy8q78ccc0wR6nMWfwAAAFjVdepgvyx+/OMfR01NTVGxz9nu99xzz7jooos6ulkAAADQLrrV19fXRxeXy93l7Pg5kZ7x9gAAAJQph3bqyfMAAACApRPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEuvUwX78+PHxkY98JAYMGBDDhg2LffbZJ5555pmqY+bMmRNHHXVUDBkyJPr37x/77bdfTJ48ucPaDAAAAO2pUwf7O+64owjt99xzT9xyyy0xf/782GOPPWLmzJmNx5xwwgnxhz/8Ia6//vri+Ndffz2+8IUvdGi7AQAAoL10q6+vr4+SePPNN4vKfQb4XXfdNaZNmxZrrLFGXH311fHFL36xOObpp5+OjTbaKCZOnBg77LDDMp13+vTpMWjQoOJ8AwcObON3AQAAQFc3vRVzaKeu2DeXbzitvvrqxc8HH3ywqOLvvvvujcdsuOGGMXr06CLYL8ncuXOLD7HpDQAAAMqoNMG+rq4ujj/++Nh5551j0003Lba98cYb0bNnz1httdWqjh0+fHixb2lj9/PKSOW29tprt3n7AQAAoEsH+xxr/8QTT8S111670ucaN25cUf2v3F555ZVWaSMAAAC0t9oogaOPPjpuvvnmuPPOO2OttdZq3D5ixIiYN29eTJ06tapqn7Pi574l6dWrV3EDAACAsuvUFfuc1y9D/Q033BC33XZbjBkzpmr/NttsEz169IgJEyY0bsvl8CZNmhQ77rhjB7QYAAAA2ldtZ+9+nzPe//73vy/Wsq+Mm89x8X369Cl+HnHEEXHiiScWE+rlTILHHHNMEeqXdUZ8AAAAKLNOvdxdt27dFrv9iiuuiMMOO6y4P2fOnDjppJPimmuuKWa733PPPeOiiy5aalf85ix3BwAAQHtqzRzaqYN9exHsAQAAaE9ddh17AAAAoJpgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACUm2AMAAECJCfYAAABQYoI9AAAAlJhgDwAAACW2ygT7n/3sZ7HuuutG7969Y/vtt4/77ruvo5sEAAAAbW6VCPbXXXddnHjiiXHGGWfEQw89FFtssUXsueeeMWXKlI5uGgAAALSpVSLYn3/++fGVr3wlDj/88Nh4443jkksuib59+8YvfvGLjm4aAAAAtKnaKLl58+bFgw8+GOPGjWvcVlNTE7vvvntMnDhxsc+ZO3ducauYNm1a8XP69Ont0GIAAAC6uumL8md9ff1Kn6v0wf6tt96KhQsXxvDhw6u25+Onn356sc8ZP358nHXWWS22r7322m3WTgAAAGju7bffjkGDBkWXDvYrIqv7OSa/YurUqbHOOuvEpEmTVvoDhc58RTAvXr3yyisxcODAjm4OtAnfc7oC33O6At9zuoJp06bF6NGjY/XVV1/pc5U+2A8dOjS6d+8ekydPrtqej0eMGLHY5/Tq1au4NZeh3j8crOryO+57zqrO95yuwPecrsD3nK6gpmblp74r/eR5PXv2jG222SYmTJjQuK2urq54vOOOO3Zo2wAAAKCtlb5in7Jb/aGHHhrbbrttbLfddnHBBRfEzJkzi1nyAQAAYFW2SgT7f/3Xf40333wzTj/99HjjjTdiyy23jD/96U8tJtRbkuyWf8YZZyy2ez6sKnzP6Qp8z+kKfM/pCnzP6Qp6teL3vFt9a8ytDwAAAHSI0o+xBwAAgK5MsAcAAIASE+wBAACgxAR7AAAAKLEuH+x/9rOfxbrrrhu9e/eO7bffPu67776ObhK0mvHjx8dHPvKRGDBgQAwbNiz22WefeOaZZzq6WdCmvv/970e3bt3i+OOP7+imQKt67bXX4t/+7d9iyJAh0adPn9hss83igQce6OhmQatZuHBhnHbaaTFmzJjiO77++uvH2WefHeb6pszuvPPO2HvvvWPUqFHF3yc33nhj1f78fufqbiNHjiy+97vvvns899xzy/06XTrYX3fddXHiiScWSww89NBDscUWW8See+4ZU6ZM6eimQau444474qijjop77rknbrnllpg/f37sscceMXPmzI5uGrSJ+++/Py699NLYfPPNO7op0Krefffd2HnnnaNHjx7xxz/+MZ588sn40Y9+FIMHD+7opkGr+cEPfhAXX3xx/PSnP42nnnqqeHzuuefGT37yk45uGqyw/Ls7c2YWlBcnv+MXXnhhXHLJJXHvvfdGv379ikw6Z86c5XqdLr3cXVbos5qZ/3ikurq6WHvtteOYY46Jb37zmx3dPGh1b775ZlG5z8C/6667dnRzoFW99957sfXWW8dFF10U55xzTmy55ZZxwQUXdHSzoFXk3yV333133HXXXR3dFGgzn/vc52L48OHx85//vHHbfvvtV1Qxr7zyyg5tG7SGrNjfcMMNRS/alFE8K/knnXRSnHzyycW2adOmFf8f/PKXv4wDDzxwmc/dZSv28+bNiwcffLDo6lBRU1NTPJ44cWKHtg3aSv5DkVZfffWObgq0uuyd8tnPfrbq33VYVdx0002x7bbbxv77719coN1qq63i8ssv7+hmQavaaaedYsKECfHss88Wjx999NH461//GnvttVdHNw3axEsvvRRvvPFG1d8ugwYNKgrQy5tJa6OLeuutt4pxPHk1pKl8/PTTT3dYu6CtZI+UHHOcXTk33XTTjm4OtKprr722GFKVXfFhVfTiiy8WXZRzCOGpp55afNePPfbY6NmzZxx66KEd3TxotZ4p06dPjw033DC6d+9e/K3+3e9+Nw4++OCObhq0iQz1aXGZtLJvWXXZYA9dsZr5xBNPFFe+YVXyyiuvxHHHHVfMI5ETocKqenE2K/bf+973isdZsc9/03NMpmDPquK3v/1tXHXVVXH11VfHJptsEo888khRlMiuyr7nsHRdtiv+0KFDiyuBkydPrtqej0eMGNFh7YK2cPTRR8fNN98cf/nLX2Kttdbq6OZAq8phVTnpaY6vr62tLW45j0RORJP3s+IDZZezJW+88cZV2zbaaKOYNGlSh7UJWtvXv/71omqf44pz1YcvfelLccIJJxSr/MCqaMSi3NkambTLBvvsurbNNtsU43iaXg3PxzvuuGOHtg1aS07IkaE+J+m47bbbiuVjYFWz2267xeOPP15Udiq3rGxm1828nxdxoexyGFXz5UpzHPI666zTYW2C1jZr1qxizqum8t/w/BsdVkVjxowpAnzTTJrDUXJ2/OXNpF26K36OU8tuPfkH4HbbbVfMnpzLERx++OEd3TRote732Z3t97//fbGWfWWsTk7KkTPMwqogv9vN543IpWJyrW/zSbCqyKplTiyWXfEPOOCAuO++++Kyyy4rbrCqyLW+c0z96NGji674Dz/8cJx//vnx5S9/uaObBiu1as/zzz9fNWFeFh5yMuv8rudwk1zNZ+zYsUXQP+2004rhJ5WZ85dVl17uLuVSdz/84Q+LwJNLI2XXzZyFEFaVJTUW54orrojDDjus3dsD7eXjH/+45e5Y5eSQqnHjxsVzzz1X/PGXBYqvfOUrHd0saDUzZswoQk32NMwhVhluDjrooDj99NOL3rZQRrfffnt84hOfaLE9C8y5pF3G8TPOOKO4UDt16tTYZZddiqV7P/ShDy3X63T5YA8AAABl1mXH2AMAAMCqQLAHAACAEhPsAQAAoMQEewAAACgxwR4AAABKTLAHAACAEhPsAQAAoMQEewAAACgxwR4AaHfdunWLG2+8saObAQCrBMEeALqYww47rAjWzW+f/vSnO7ppAMAKqF2RJwEA5ZYh/oorrqja1qtXrw5rDwCw4lTsAaALyhA/YsSIqtvgwYOLfVm9v/jii2OvvfaKPn36xHrrrRe/+93vqp7/+OOPxyc/+cli/5AhQ+LII4+M9957r+qYX/ziF7HJJpsUrzVy5Mg4+uijq/a/9dZbse+++0bfvn1j7NixcdNNN7XDOweAVY9gDwC0cNppp8V+++0Xjz76aBx88MFx4IEHxlNPPVXsmzlzZuy5557FhYD7778/rr/++rj11lurgnteGDjqqKOKwJ8XATK0b7DBBlWvcdZZZ8UBBxwQjz32WHzmM58pXuedd95p9/cKAGXXrb6+vr6jGwEAtO8Y+yuvvDJ69+5dtf3UU08tblmx//d///cinFfssMMOsfXWW8dFF10Ul19+eXzjG9+IV155Jfr161fs/+///u/Ye++94/XXX4/hw4fHmmuuGYcffnicc845i21Dvsa3v/3tOPvssxsvFvTv3z/++Mc/GusPAMvJGHsA6II+8YlPVAX3tPrqqzfe33HHHav25eNHHnmkuJ+V+y222KIx1Kedd9456urq4plnnilCewb83Xbbbalt2HzzzRvv57kGDhwYU6ZMWen3BgBdjWAPAF1QBunmXeNbS467XxY9evSoepwXBPLiAACwfIyxBwBauOeee1o83mijjYr7+TPH3mf3+Yq77747ampq4sMf/nAMGDAg1l133ZgwYUK7txsAuiIVewDogubOnRtvvPFG1bba2toYOnRocT8nxNt2221jl112iauuuiruu++++PnPf17sy0nuzjjjjDj00EPjzDPPjDfffDOOOeaY+NKXvlSMr0+5PcfpDxs2rJhdf8aMGUX4z+MAgNYl2ANAF/SnP/2pWIKuqay2P/30040z1l977bXxta99rTjummuuiY033rjYl8vT/fnPf47jjjsuPvKRjxSPcwb9888/v/FcGfrnzJkTP/7xj+Pkk08uLhh88YtfbOd3CQBdg1nxAYAWY91vuOGG2GeffTq6KQDAMjDGHgAAAEpMsAcAAIASM8YeAKhilB4AlIuKPQAAAJSYYA8AAAAlJtgDAABAiQn2AAAAUGKCPQAAAJSYYA8AAAAlJtgDAABAiQn2AAAAEOX1/wF2Ncx5b/dbaQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Training model on {device}\")\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "loss_values = []\n",
    "epoch_losses = []\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_epoch = -1\n",
    "\n",
    "best_acc = 0.0\n",
    "best_epoch_acc = -1\n",
    "\n",
    "test_accuracies = []\n",
    "test_class_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move inputs and labels to the appropriate device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform a forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        # Perform a backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model's weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss statistics\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        count += 1\n",
    "\n",
    "        if i % 50 == 49:    # print every 200 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "            # Display the loss curve\n",
    "            display_loss(loss_values)\n",
    "            display_epochloss(epoch_losses, val_losses)\n",
    "            clear_output(wait=True)\n",
    "  \n",
    "    epoch_losses.append(epoch_loss/350)\n",
    "\n",
    "    val_loss = compute_val_loss(model, validation_loader, criterion)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "\n",
    "        torch.save(model.state_dict(), 'best_cifar10_resnet18.pth')\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Compute accuracy on the test set\n",
    "    test_accuracy, class_accuracy = compute_accuracy(model, test_loader)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    test_class_accuracies.append(class_accuracy)\n",
    "\n",
    "    if test_accuracy > best_acc:\n",
    "        best_acc = test_accuracy\n",
    "        best_epoch_acc = epoch\n",
    "        torch.save(model.state_dict(), 'best_acc_cifar10_resnet18.pth')\n",
    "\n",
    "    display_accuracy(test_accuracies)\n",
    "   \n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(model.state_dict(), 'cifar10_resnet18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 69.96 %\n",
      "Class-wise accuracies:\n",
      "Class 0: 75.80 %\n",
      "Class 1: 87.10 %\n",
      "Class 2: 60.20 %\n",
      "Class 3: 52.50 %\n",
      "Class 4: 61.80 %\n",
      "Class 5: 62.00 %\n",
      "Class 6: 70.10 %\n",
      "Class 7: 76.70 %\n",
      "Class 8: 81.00 %\n",
      "Class 9: 72.40 %\n"
     ]
    }
   ],
   "source": [
    "accuracy, class_accuracies = compute_accuracy(model, test_loader)\n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f} %')\n",
    "print('Class-wise accuracies:')\n",
    "for i in range(10):\n",
    "    print(f'Class {i}: {class_accuracies[i]:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance set split by class:\n",
      "  Class 'cat': 517 samples\n",
      "  Class 'dog': 503 samples\n",
      "  Class 'deer': 507 samples\n",
      "  Class 'ship': 497 samples\n",
      "  Class 'frog': 493 samples\n",
      "  Class 'bird': 505 samples\n",
      "  Class 'automobile': 490 samples\n",
      "  Class 'horse': 472 samples\n",
      "  Class 'airplane': 519 samples\n",
      "  Class 'truck': 497 samples\n"
     ]
    }
   ],
   "source": [
    "# Split importance set by class\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Get class names from the dataset\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Create a dictionary to hold samples for each class\n",
    "importance_by_class = defaultdict(list)\n",
    "\n",
    "# Iterate through the importance_subset and split by class\n",
    "for idx in importance_subset.indices:\n",
    "    # Get the original dataset item and its class label\n",
    "    # Note: importance_subset is a Subset, so we need to access its dataset attribute\n",
    "    # and then get the item by its original index.\n",
    "    _, label = train_dataset[idx]\n",
    "    class_name = class_names[label]\n",
    "    importance_by_class[class_name].append(train_dataset[idx])\n",
    "\n",
    "print(\"Importance set split by class:\")\n",
    "for class_name, samples in importance_by_class.items():\n",
    "    print(f\"  Class '{class_name}': {len(samples)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-datapoint DataLoaders created for importance classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute parameter L1 norms for each class\n",
    "\n",
    "# Create DataLoaders with batch_size=1 for per-datapoint gradient analysis\n",
    "per_datapoint_dataloaders = {}\n",
    "for class_name, samples in importance_by_class.items():\n",
    "    per_datapoint_dataloaders[class_name] = DataLoader(samples, batch_size=len(samples), shuffle=False)\n",
    "\n",
    "print(\"Per-datapoint DataLoaders created for importance classes.\")\n",
    "\n",
    "datapoint_param_l1_norms = {class_name: [] for class_name in class_names}\n",
    "\n",
    "model.eval() # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad(): # Outer no_grad block for general operation\n",
    "    for class_name, data_loader in per_datapoint_dataloaders.items():\n",
    "        class_norms = []\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.enable_grad(): # Enable grad only for the loss calculation\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                model.zero_grad() # Zero gradients for this specific datapoint\n",
    "                loss.backward()\n",
    "\n",
    "                # Collect L1 norm of gradients for each parameter for this datapoint\n",
    "                current_datapoint_param_norms = {}\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        current_datapoint_param_norms[name] = torch.norm(param.grad, p=1).item()\n",
    "                    else:\n",
    "                        current_datapoint_param_norms[name] = 0.0\n",
    "                class_norms.append(current_datapoint_param_norms)\n",
    "\n",
    "        datapoint_param_l1_norms[class_name] = class_norms\n",
    "\n",
    "model.train() # Reset model to training mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': [{'conv1.weight': 93.09488677978516, 'bn1.weight': 0.2949860095977783, 'bn1.bias': 0.9864556193351746, 'layer1.0.conv1.weight': 73.61775207519531, 'layer1.0.bn1.weight': 0.1968373954296112, 'layer1.0.bn1.bias': 0.6792192459106445, 'layer1.0.conv2.weight': 80.63255310058594, 'layer1.0.bn2.weight': 0.230294868350029, 'layer1.0.bn2.bias': 1.0418732166290283, 'layer1.1.conv1.weight': 87.55230712890625, 'layer1.1.bn1.weight': 0.24405138194561005, 'layer1.1.bn1.bias': 0.5640832781791687, 'layer1.1.conv2.weight': 101.27618408203125, 'layer1.1.bn2.weight': 0.23329201340675354, 'layer1.1.bn2.bias': 0.975649356842041, 'layer2.0.conv1.weight': 161.82977294921875, 'layer2.0.bn1.weight': 0.3451741635799408, 'layer2.0.bn1.bias': 0.840376615524292, 'layer2.0.conv2.weight': 236.7536163330078, 'layer2.0.bn2.weight': 0.40090662240982056, 'layer2.0.bn2.bias': 1.394970178604126, 'layer2.0.downsample.0.weight': 28.244354248046875, 'layer2.0.downsample.1.weight': 0.4165607988834381, 'layer2.0.downsample.1.bias': 1.394970178604126, 'layer2.1.conv1.weight': 272.8011169433594, 'layer2.1.bn1.weight': 0.45924249291419983, 'layer2.1.bn1.bias': 1.0785895586013794, 'layer2.1.conv2.weight': 292.64459228515625, 'layer2.1.bn2.weight': 0.49057644605636597, 'layer2.1.bn2.bias': 1.5773905515670776, 'layer3.0.conv1.weight': 644.1712036132812, 'layer3.0.bn1.weight': 0.750715434551239, 'layer3.0.bn1.bias': 1.5666824579238892, 'layer3.0.conv2.weight': 692.2122802734375, 'layer3.0.bn2.weight': 0.6834148168563843, 'layer3.0.bn2.bias': 2.3756611347198486, 'layer3.0.downsample.0.weight': 96.45172119140625, 'layer3.0.downsample.1.weight': 0.9324091672897339, 'layer3.0.downsample.1.bias': 2.3756611347198486, 'layer3.1.conv1.weight': 675.9895629882812, 'layer3.1.bn1.weight': 0.6527437567710876, 'layer3.1.bn1.bias': 1.726965308189392, 'layer3.1.conv2.weight': 639.1650390625, 'layer3.1.bn2.weight': 0.6608100533485413, 'layer3.1.bn2.bias': 3.1433873176574707, 'layer4.0.conv1.weight': 549.0866088867188, 'layer4.0.bn1.weight': 0.48965585231781006, 'layer4.0.bn1.bias': 1.6666512489318848, 'layer4.0.conv2.weight': 378.73016357421875, 'layer4.0.bn2.weight': 0.43593457341194153, 'layer4.0.bn2.bias': 5.144650459289551, 'layer4.0.downsample.0.weight': 379.87811279296875, 'layer4.0.downsample.1.weight': 1.9606181383132935, 'layer4.0.downsample.1.bias': 5.144650459289551, 'layer4.1.conv1.weight': 199.3954620361328, 'layer4.1.bn1.weight': 0.23516780138015747, 'layer4.1.bn1.bias': 1.986002802848816, 'layer4.1.conv2.weight': 258.4543151855469, 'layer4.1.bn2.weight': 0.33564841747283936, 'layer4.1.bn2.bias': 7.670624732971191, 'fc.weight': 188.521240234375, 'fc.bias': 1.8070822954177856}], 'automobile': [{'conv1.weight': 99.9708251953125, 'bn1.weight': 0.4723351299762726, 'bn1.bias': 1.4952583312988281, 'layer1.0.conv1.weight': 107.25581359863281, 'layer1.0.bn1.weight': 0.2875302731990814, 'layer1.0.bn1.bias': 0.7360710501670837, 'layer1.0.conv2.weight': 106.635009765625, 'layer1.0.bn2.weight': 0.2743242681026459, 'layer1.0.bn2.bias': 1.1945751905441284, 'layer1.1.conv1.weight': 116.81861877441406, 'layer1.1.bn1.weight': 0.346280962228775, 'layer1.1.bn1.bias': 0.6329461932182312, 'layer1.1.conv2.weight': 120.23631286621094, 'layer1.1.bn2.weight': 0.273947149515152, 'layer1.1.bn2.bias': 1.0033714771270752, 'layer2.0.conv1.weight': 228.11502075195312, 'layer2.0.bn1.weight': 0.4892921447753906, 'layer2.0.bn1.bias': 1.0525569915771484, 'layer2.0.conv2.weight': 301.8134765625, 'layer2.0.bn2.weight': 0.5059032440185547, 'layer2.0.bn2.bias': 1.5383614301681519, 'layer2.0.downsample.0.weight': 37.8609504699707, 'layer2.0.downsample.1.weight': 0.596854567527771, 'layer2.0.downsample.1.bias': 1.5383614301681519, 'layer2.1.conv1.weight': 333.36328125, 'layer2.1.bn1.weight': 0.5833671689033508, 'layer2.1.bn1.bias': 1.2102043628692627, 'layer2.1.conv2.weight': 400.0797424316406, 'layer2.1.bn2.weight': 0.6548895835876465, 'layer2.1.bn2.bias': 1.9324477910995483, 'layer3.0.conv1.weight': 774.5001220703125, 'layer3.0.bn1.weight': 0.9510712027549744, 'layer3.0.bn1.bias': 1.696627140045166, 'layer3.0.conv2.weight': 855.6111450195312, 'layer3.0.bn2.weight': 0.8565371632575989, 'layer3.0.bn2.bias': 2.600130796432495, 'layer3.0.downsample.0.weight': 119.1539077758789, 'layer3.0.downsample.1.weight': 1.078373908996582, 'layer3.0.downsample.1.bias': 2.600130796432495, 'layer3.1.conv1.weight': 830.2398071289062, 'layer3.1.bn1.weight': 0.7892802953720093, 'layer3.1.bn1.bias': 1.8851442337036133, 'layer3.1.conv2.weight': 710.707275390625, 'layer3.1.bn2.weight': 0.6995677947998047, 'layer3.1.bn2.bias': 3.083303213119507, 'layer4.0.conv1.weight': 579.0201416015625, 'layer4.0.bn1.weight': 0.5040081143379211, 'layer4.0.bn1.bias': 1.5384541749954224, 'layer4.0.conv2.weight': 414.5741271972656, 'layer4.0.bn2.weight': 0.4870275557041168, 'layer4.0.bn2.bias': 4.879399299621582, 'layer4.0.downsample.0.weight': 416.99652099609375, 'layer4.0.downsample.1.weight': 2.0095043182373047, 'layer4.0.downsample.1.bias': 4.879399299621582, 'layer4.1.conv1.weight': 208.87474060058594, 'layer4.1.bn1.weight': 0.26245740056037903, 'layer4.1.bn1.bias': 1.833617091178894, 'layer4.1.conv2.weight': 285.548583984375, 'layer4.1.bn2.weight': 0.34504687786102295, 'layer4.1.bn2.bias': 7.443964958190918, 'fc.weight': 211.8446044921875, 'fc.bias': 1.7869027853012085}], 'bird': [{'conv1.weight': 85.234375, 'bn1.weight': 0.3490413427352905, 'bn1.bias': 1.4164389371871948, 'layer1.0.conv1.weight': 80.0821762084961, 'layer1.0.bn1.weight': 0.21159937977790833, 'layer1.0.bn1.bias': 0.6549720168113708, 'layer1.0.conv2.weight': 94.29121398925781, 'layer1.0.bn2.weight': 0.17744465172290802, 'layer1.0.bn2.bias': 1.1818510293960571, 'layer1.1.conv1.weight': 111.04802703857422, 'layer1.1.bn1.weight': 0.3571348488330841, 'layer1.1.bn1.bias': 0.7786791324615479, 'layer1.1.conv2.weight': 101.55642700195312, 'layer1.1.bn2.weight': 0.2563217282295227, 'layer1.1.bn2.bias': 1.0328853130340576, 'layer2.0.conv1.weight': 173.18917846679688, 'layer2.0.bn1.weight': 0.3324201703071594, 'layer2.0.bn1.bias': 0.9079219698905945, 'layer2.0.conv2.weight': 245.96348571777344, 'layer2.0.bn2.weight': 0.42628276348114014, 'layer2.0.bn2.bias': 1.476858139038086, 'layer2.0.downsample.0.weight': 29.555692672729492, 'layer2.0.downsample.1.weight': 0.4426422119140625, 'layer2.0.downsample.1.bias': 1.476858139038086, 'layer2.1.conv1.weight': 261.4861755371094, 'layer2.1.bn1.weight': 0.4411984086036682, 'layer2.1.bn1.bias': 1.0828183889389038, 'layer2.1.conv2.weight': 341.5504455566406, 'layer2.1.bn2.weight': 0.5885229706764221, 'layer2.1.bn2.bias': 1.9062206745147705, 'layer3.0.conv1.weight': 713.9357299804688, 'layer3.0.bn1.weight': 0.8222329616546631, 'layer3.0.bn1.bias': 1.870855689048767, 'layer3.0.conv2.weight': 803.2518920898438, 'layer3.0.bn2.weight': 0.9654670357704163, 'layer3.0.bn2.bias': 2.934361696243286, 'layer3.0.downsample.0.weight': 111.8313217163086, 'layer3.0.downsample.1.weight': 0.9492825865745544, 'layer3.0.downsample.1.bias': 2.934361696243286, 'layer3.1.conv1.weight': 754.91748046875, 'layer3.1.bn1.weight': 0.7755401730537415, 'layer3.1.bn1.bias': 2.1319310665130615, 'layer3.1.conv2.weight': 635.5409545898438, 'layer3.1.bn2.weight': 0.6786929368972778, 'layer3.1.bn2.bias': 3.3222737312316895, 'layer4.0.conv1.weight': 501.2120666503906, 'layer4.0.bn1.weight': 0.4437166452407837, 'layer4.0.bn1.bias': 1.583782434463501, 'layer4.0.conv2.weight': 383.8764953613281, 'layer4.0.bn2.weight': 0.444568008184433, 'layer4.0.bn2.bias': 5.353424072265625, 'layer4.0.downsample.0.weight': 383.05914306640625, 'layer4.0.downsample.1.weight': 1.9045666456222534, 'layer4.0.downsample.1.bias': 5.353424072265625, 'layer4.1.conv1.weight': 182.63772583007812, 'layer4.1.bn1.weight': 0.23167137801647186, 'layer4.1.bn1.bias': 1.9205598831176758, 'layer4.1.conv2.weight': 257.8779296875, 'layer4.1.bn2.weight': 0.3270263671875, 'layer4.1.bn2.bias': 8.019668579101562, 'fc.weight': 179.51783752441406, 'fc.bias': 1.815758228302002}], 'cat': [{'conv1.weight': 95.59966278076172, 'bn1.weight': 0.39669060707092285, 'bn1.bias': 1.1645792722702026, 'layer1.0.conv1.weight': 80.64580535888672, 'layer1.0.bn1.weight': 0.20568352937698364, 'layer1.0.bn1.bias': 0.5156785845756531, 'layer1.0.conv2.weight': 89.06192016601562, 'layer1.0.bn2.weight': 0.19745267927646637, 'layer1.0.bn2.bias': 0.8400050401687622, 'layer1.1.conv1.weight': 98.43330383300781, 'layer1.1.bn1.weight': 0.30400246381759644, 'layer1.1.bn1.bias': 0.5628646016120911, 'layer1.1.conv2.weight': 108.94694519042969, 'layer1.1.bn2.weight': 0.2400389313697815, 'layer1.1.bn2.bias': 0.8632024526596069, 'layer2.0.conv1.weight': 203.28802490234375, 'layer2.0.bn1.weight': 0.42713525891304016, 'layer2.0.bn1.bias': 0.8984435796737671, 'layer2.0.conv2.weight': 261.7263488769531, 'layer2.0.bn2.weight': 0.4782974123954773, 'layer2.0.bn2.bias': 1.2672698497772217, 'layer2.0.downsample.0.weight': 29.816452026367188, 'layer2.0.downsample.1.weight': 0.396767258644104, 'layer2.0.downsample.1.bias': 1.2672698497772217, 'layer2.1.conv1.weight': 287.2484436035156, 'layer2.1.bn1.weight': 0.4895161986351013, 'layer2.1.bn1.bias': 1.0191357135772705, 'layer2.1.conv2.weight': 372.807373046875, 'layer2.1.bn2.weight': 0.6727890968322754, 'layer2.1.bn2.bias': 1.9116655588150024, 'layer3.0.conv1.weight': 728.1762084960938, 'layer3.0.bn1.weight': 0.8166561126708984, 'layer3.0.bn1.bias': 1.6757980585098267, 'layer3.0.conv2.weight': 777.3492431640625, 'layer3.0.bn2.weight': 0.7801032662391663, 'layer3.0.bn2.bias': 2.4775280952453613, 'layer3.0.downsample.0.weight': 107.6875, 'layer3.0.downsample.1.weight': 1.0173931121826172, 'layer3.0.downsample.1.bias': 2.4775280952453613, 'layer3.1.conv1.weight': 786.1414794921875, 'layer3.1.bn1.weight': 0.7916085720062256, 'layer3.1.bn1.bias': 1.9615435600280762, 'layer3.1.conv2.weight': 689.0994262695312, 'layer3.1.bn2.weight': 0.7191526889801025, 'layer3.1.bn2.bias': 3.107457160949707, 'layer4.0.conv1.weight': 577.3569946289062, 'layer4.0.bn1.weight': 0.4960860311985016, 'layer4.0.bn1.bias': 1.5971616506576538, 'layer4.0.conv2.weight': 430.39776611328125, 'layer4.0.bn2.weight': 0.4882577955722809, 'layer4.0.bn2.bias': 5.228686332702637, 'layer4.0.downsample.0.weight': 429.0986328125, 'layer4.0.downsample.1.weight': 2.1700069904327393, 'layer4.0.downsample.1.bias': 5.228686332702637, 'layer4.1.conv1.weight': 213.14773559570312, 'layer4.1.bn1.weight': 0.27741068601608276, 'layer4.1.bn1.bias': 1.9621275663375854, 'layer4.1.conv2.weight': 283.60595703125, 'layer4.1.bn2.weight': 0.3583764433860779, 'layer4.1.bn2.bias': 7.68412446975708, 'fc.weight': 199.62744140625, 'fc.bias': 1.7641897201538086}], 'deer': [{'conv1.weight': 85.37320709228516, 'bn1.weight': 0.3856979012489319, 'bn1.bias': 1.2864941358566284, 'layer1.0.conv1.weight': 82.10076904296875, 'layer1.0.bn1.weight': 0.19401471316814423, 'layer1.0.bn1.bias': 0.7342986464500427, 'layer1.0.conv2.weight': 78.30982971191406, 'layer1.0.bn2.weight': 0.1958237588405609, 'layer1.0.bn2.bias': 1.015326976776123, 'layer1.1.conv1.weight': 94.59785461425781, 'layer1.1.bn1.weight': 0.26623111963272095, 'layer1.1.bn1.bias': 0.6496736407279968, 'layer1.1.conv2.weight': 101.46180725097656, 'layer1.1.bn2.weight': 0.2539505064487457, 'layer1.1.bn2.bias': 1.027366042137146, 'layer2.0.conv1.weight': 163.9732666015625, 'layer2.0.bn1.weight': 0.3640730381011963, 'layer2.0.bn1.bias': 0.8564515113830566, 'layer2.0.conv2.weight': 222.55258178710938, 'layer2.0.bn2.weight': 0.36651280522346497, 'layer2.0.bn2.bias': 1.1973106861114502, 'layer2.0.downsample.0.weight': 25.559480667114258, 'layer2.0.downsample.1.weight': 0.38019728660583496, 'layer2.0.downsample.1.bias': 1.1973106861114502, 'layer2.1.conv1.weight': 255.91302490234375, 'layer2.1.bn1.weight': 0.4460703432559967, 'layer2.1.bn1.bias': 1.123752474784851, 'layer2.1.conv2.weight': 300.88568115234375, 'layer2.1.bn2.weight': 0.5612233877182007, 'layer2.1.bn2.bias': 1.6762733459472656, 'layer3.0.conv1.weight': 584.232421875, 'layer3.0.bn1.weight': 0.5616084933280945, 'layer3.0.bn1.bias': 1.5292168855667114, 'layer3.0.conv2.weight': 668.2784423828125, 'layer3.0.bn2.weight': 0.6779394745826721, 'layer3.0.bn2.bias': 2.486713171005249, 'layer3.0.downsample.0.weight': 94.91064453125, 'layer3.0.downsample.1.weight': 0.8797796964645386, 'layer3.0.downsample.1.bias': 2.486713171005249, 'layer3.1.conv1.weight': 692.2449951171875, 'layer3.1.bn1.weight': 0.672650158405304, 'layer3.1.bn1.bias': 1.9815936088562012, 'layer3.1.conv2.weight': 598.0016479492188, 'layer3.1.bn2.weight': 0.615502119064331, 'layer3.1.bn2.bias': 3.115570306777954, 'layer4.0.conv1.weight': 498.120849609375, 'layer4.0.bn1.weight': 0.4405430555343628, 'layer4.0.bn1.bias': 1.5980018377304077, 'layer4.0.conv2.weight': 381.7982482910156, 'layer4.0.bn2.weight': 0.4505079984664917, 'layer4.0.bn2.bias': 5.357222080230713, 'layer4.0.downsample.0.weight': 376.7118225097656, 'layer4.0.downsample.1.weight': 1.8889214992523193, 'layer4.0.downsample.1.bias': 5.357222080230713, 'layer4.1.conv1.weight': 193.76162719726562, 'layer4.1.bn1.weight': 0.24613001942634583, 'layer4.1.bn1.bias': 2.0894699096679688, 'layer4.1.conv2.weight': 250.3956756591797, 'layer4.1.bn2.weight': 0.3031448721885681, 'layer4.1.bn2.bias': 7.95579719543457, 'fc.weight': 178.76783752441406, 'fc.bias': 1.8497653007507324}], 'dog': [{'conv1.weight': 88.54503631591797, 'bn1.weight': 0.39345985651016235, 'bn1.bias': 1.2235642671585083, 'layer1.0.conv1.weight': 87.46463012695312, 'layer1.0.bn1.weight': 0.2536087930202484, 'layer1.0.bn1.bias': 0.7440999746322632, 'layer1.0.conv2.weight': 85.07620239257812, 'layer1.0.bn2.weight': 0.24667991697788239, 'layer1.0.bn2.bias': 0.9736360907554626, 'layer1.1.conv1.weight': 98.39053344726562, 'layer1.1.bn1.weight': 0.28408145904541016, 'layer1.1.bn1.bias': 0.6165845394134521, 'layer1.1.conv2.weight': 108.49310302734375, 'layer1.1.bn2.weight': 0.27212807536125183, 'layer1.1.bn2.bias': 1.0037710666656494, 'layer2.0.conv1.weight': 172.74465942382812, 'layer2.0.bn1.weight': 0.3686882257461548, 'layer2.0.bn1.bias': 0.8380071520805359, 'layer2.0.conv2.weight': 234.88882446289062, 'layer2.0.bn2.weight': 0.37570998072624207, 'layer2.0.bn2.bias': 1.272533893585205, 'layer2.0.downsample.0.weight': 28.06658172607422, 'layer2.0.downsample.1.weight': 0.4506811499595642, 'layer2.0.downsample.1.bias': 1.272533893585205, 'layer2.1.conv1.weight': 258.0105285644531, 'layer2.1.bn1.weight': 0.465335488319397, 'layer2.1.bn1.bias': 0.9574342370033264, 'layer2.1.conv2.weight': 326.81329345703125, 'layer2.1.bn2.weight': 0.5551227927207947, 'layer2.1.bn2.bias': 1.7025905847549438, 'layer3.0.conv1.weight': 682.968994140625, 'layer3.0.bn1.weight': 0.7747889757156372, 'layer3.0.bn1.bias': 1.5560003519058228, 'layer3.0.conv2.weight': 715.6099853515625, 'layer3.0.bn2.weight': 0.7555106282234192, 'layer3.0.bn2.bias': 2.143395185470581, 'layer3.0.downsample.0.weight': 93.96656036376953, 'layer3.0.downsample.1.weight': 0.7713707089424133, 'layer3.0.downsample.1.bias': 2.143395185470581, 'layer3.1.conv1.weight': 750.3267211914062, 'layer3.1.bn1.weight': 0.7821840643882751, 'layer3.1.bn1.bias': 1.7940860986709595, 'layer3.1.conv2.weight': 617.9196166992188, 'layer3.1.bn2.weight': 0.6019865870475769, 'layer3.1.bn2.bias': 2.7346596717834473, 'layer4.0.conv1.weight': 492.19268798828125, 'layer4.0.bn1.weight': 0.41620999574661255, 'layer4.0.bn1.bias': 1.329969048500061, 'layer4.0.conv2.weight': 390.2791442871094, 'layer4.0.bn2.weight': 0.45175406336784363, 'layer4.0.bn2.bias': 4.6814351081848145, 'layer4.0.downsample.0.weight': 390.56951904296875, 'layer4.0.downsample.1.weight': 1.9671248197555542, 'layer4.0.downsample.1.bias': 4.6814351081848145, 'layer4.1.conv1.weight': 217.17608642578125, 'layer4.1.bn1.weight': 0.27001047134399414, 'layer4.1.bn1.bias': 1.962148666381836, 'layer4.1.conv2.weight': 265.9263000488281, 'layer4.1.bn2.weight': 0.32071807980537415, 'layer4.1.bn2.bias': 7.14168643951416, 'fc.weight': 199.6325225830078, 'fc.bias': 1.730948805809021}], 'frog': [{'conv1.weight': 73.4692153930664, 'bn1.weight': 0.2959410846233368, 'bn1.bias': 1.1358470916748047, 'layer1.0.conv1.weight': 90.75541687011719, 'layer1.0.bn1.weight': 0.21655243635177612, 'layer1.0.bn1.bias': 0.7270944118499756, 'layer1.0.conv2.weight': 77.6774673461914, 'layer1.0.bn2.weight': 0.17748889327049255, 'layer1.0.bn2.bias': 0.8877763748168945, 'layer1.1.conv1.weight': 102.85346221923828, 'layer1.1.bn1.weight': 0.32319191098213196, 'layer1.1.bn1.bias': 0.6730659604072571, 'layer1.1.conv2.weight': 102.66056060791016, 'layer1.1.bn2.weight': 0.3053765296936035, 'layer1.1.bn2.bias': 1.0130001306533813, 'layer2.0.conv1.weight': 173.3148193359375, 'layer2.0.bn1.weight': 0.3372182846069336, 'layer2.0.bn1.bias': 0.8005079627037048, 'layer2.0.conv2.weight': 232.65676879882812, 'layer2.0.bn2.weight': 0.39384138584136963, 'layer2.0.bn2.bias': 1.2725106477737427, 'layer2.0.downsample.0.weight': 27.900924682617188, 'layer2.0.downsample.1.weight': 0.3702158033847809, 'layer2.0.downsample.1.bias': 1.2725106477737427, 'layer2.1.conv1.weight': 276.11676025390625, 'layer2.1.bn1.weight': 0.4772889018058777, 'layer2.1.bn1.bias': 1.0084753036499023, 'layer2.1.conv2.weight': 339.1263732910156, 'layer2.1.bn2.weight': 0.5632817149162292, 'layer2.1.bn2.bias': 1.6708259582519531, 'layer3.0.conv1.weight': 711.990966796875, 'layer3.0.bn1.weight': 0.8090614080429077, 'layer3.0.bn1.bias': 1.7121697664260864, 'layer3.0.conv2.weight': 755.231689453125, 'layer3.0.bn2.weight': 0.8253719210624695, 'layer3.0.bn2.bias': 2.4415860176086426, 'layer3.0.downsample.0.weight': 105.17928314208984, 'layer3.0.downsample.1.weight': 0.9294155836105347, 'layer3.0.downsample.1.bias': 2.4415860176086426, 'layer3.1.conv1.weight': 760.94677734375, 'layer3.1.bn1.weight': 0.7510639429092407, 'layer3.1.bn1.bias': 1.924941897392273, 'layer3.1.conv2.weight': 636.3115234375, 'layer3.1.bn2.weight': 0.6576085090637207, 'layer3.1.bn2.bias': 3.030473470687866, 'layer4.0.conv1.weight': 511.66741943359375, 'layer4.0.bn1.weight': 0.4428131580352783, 'layer4.0.bn1.bias': 1.4671978950500488, 'layer4.0.conv2.weight': 402.6506042480469, 'layer4.0.bn2.weight': 0.4761093854904175, 'layer4.0.bn2.bias': 5.045175075531006, 'layer4.0.downsample.0.weight': 398.7559509277344, 'layer4.0.downsample.1.weight': 1.9885848760604858, 'layer4.0.downsample.1.bias': 5.045175075531006, 'layer4.1.conv1.weight': 204.1578369140625, 'layer4.1.bn1.weight': 0.2543502449989319, 'layer4.1.bn1.bias': 1.967612624168396, 'layer4.1.conv2.weight': 268.95306396484375, 'layer4.1.bn2.weight': 0.32454267144203186, 'layer4.1.bn2.bias': 7.698010444641113, 'fc.weight': 194.2245635986328, 'fc.bias': 1.7975438833236694}], 'horse': [{'conv1.weight': 101.28894805908203, 'bn1.weight': 0.5114227533340454, 'bn1.bias': 1.526517629623413, 'layer1.0.conv1.weight': 111.47354125976562, 'layer1.0.bn1.weight': 0.2629653513431549, 'layer1.0.bn1.bias': 0.6859208345413208, 'layer1.0.conv2.weight': 111.07958221435547, 'layer1.0.bn2.weight': 0.24031412601470947, 'layer1.0.bn2.bias': 1.0898767709732056, 'layer1.1.conv1.weight': 124.07696533203125, 'layer1.1.bn1.weight': 0.3563194274902344, 'layer1.1.bn1.bias': 0.7135776877403259, 'layer1.1.conv2.weight': 138.61349487304688, 'layer1.1.bn2.weight': 0.32247981429100037, 'layer1.1.bn2.bias': 1.0393034219741821, 'layer2.0.conv1.weight': 216.53274536132812, 'layer2.0.bn1.weight': 0.4624338746070862, 'layer2.0.bn1.bias': 0.9668608903884888, 'layer2.0.conv2.weight': 318.29730224609375, 'layer2.0.bn2.weight': 0.5625975131988525, 'layer2.0.bn2.bias': 1.5152076482772827, 'layer2.0.downsample.0.weight': 37.38923645019531, 'layer2.0.downsample.1.weight': 0.5540759563446045, 'layer2.0.downsample.1.bias': 1.5152076482772827, 'layer2.1.conv1.weight': 317.38909912109375, 'layer2.1.bn1.weight': 0.5085334777832031, 'layer2.1.bn1.bias': 1.1234428882598877, 'layer2.1.conv2.weight': 402.8927001953125, 'layer2.1.bn2.weight': 0.6802452206611633, 'layer2.1.bn2.bias': 1.8364543914794922, 'layer3.0.conv1.weight': 840.246826171875, 'layer3.0.bn1.weight': 0.9075337648391724, 'layer3.0.bn1.bias': 1.7497681379318237, 'layer3.0.conv2.weight': 870.8828735351562, 'layer3.0.bn2.weight': 0.9560470581054688, 'layer3.0.bn2.bias': 2.6123130321502686, 'layer3.0.downsample.0.weight': 120.3872299194336, 'layer3.0.downsample.1.weight': 1.1119636297225952, 'layer3.0.downsample.1.bias': 2.6123130321502686, 'layer3.1.conv1.weight': 876.906005859375, 'layer3.1.bn1.weight': 0.9016175270080566, 'layer3.1.bn1.bias': 2.020435333251953, 'layer3.1.conv2.weight': 792.5587768554688, 'layer3.1.bn2.weight': 0.8571063876152039, 'layer3.1.bn2.bias': 3.3823063373565674, 'layer4.0.conv1.weight': 633.77734375, 'layer4.0.bn1.weight': 0.5723575949668884, 'layer4.0.bn1.bias': 1.6629306077957153, 'layer4.0.conv2.weight': 443.8070068359375, 'layer4.0.bn2.weight': 0.5257713198661804, 'layer4.0.bn2.bias': 5.1214280128479, 'layer4.0.downsample.0.weight': 441.22857666015625, 'layer4.0.downsample.1.weight': 2.1717820167541504, 'layer4.0.downsample.1.bias': 5.1214280128479, 'layer4.1.conv1.weight': 213.7399139404297, 'layer4.1.bn1.weight': 0.26848268508911133, 'layer4.1.bn1.bias': 1.8664278984069824, 'layer4.1.conv2.weight': 295.4501953125, 'layer4.1.bn2.weight': 0.3624517321586609, 'layer4.1.bn2.bias': 7.629717826843262, 'fc.weight': 221.17587280273438, 'fc.bias': 1.8527631759643555}], 'ship': [{'conv1.weight': 132.15042114257812, 'bn1.weight': 0.41280925273895264, 'bn1.bias': 1.1785783767700195, 'layer1.0.conv1.weight': 80.61528015136719, 'layer1.0.bn1.weight': 0.20964403450489044, 'layer1.0.bn1.bias': 0.655554473400116, 'layer1.0.conv2.weight': 96.93002319335938, 'layer1.0.bn2.weight': 0.2879563271999359, 'layer1.0.bn2.bias': 1.1380784511566162, 'layer1.1.conv1.weight': 101.22364044189453, 'layer1.1.bn1.weight': 0.30203723907470703, 'layer1.1.bn1.bias': 0.6513868570327759, 'layer1.1.conv2.weight': 114.11860656738281, 'layer1.1.bn2.weight': 0.23491385579109192, 'layer1.1.bn2.bias': 1.0493377447128296, 'layer2.0.conv1.weight': 181.39486694335938, 'layer2.0.bn1.weight': 0.3902813792228699, 'layer2.0.bn1.bias': 0.923330545425415, 'layer2.0.conv2.weight': 250.51089477539062, 'layer2.0.bn2.weight': 0.47344452142715454, 'layer2.0.bn2.bias': 1.4365729093551636, 'layer2.0.downsample.0.weight': 30.16438865661621, 'layer2.0.downsample.1.weight': 0.40324464440345764, 'layer2.0.downsample.1.bias': 1.4365729093551636, 'layer2.1.conv1.weight': 264.3865661621094, 'layer2.1.bn1.weight': 0.3958047330379486, 'layer2.1.bn1.bias': 0.9795873165130615, 'layer2.1.conv2.weight': 315.0000915527344, 'layer2.1.bn2.weight': 0.4741029739379883, 'layer2.1.bn2.bias': 1.8070629835128784, 'layer3.0.conv1.weight': 640.3292846679688, 'layer3.0.bn1.weight': 0.7288200259208679, 'layer3.0.bn1.bias': 1.7496825456619263, 'layer3.0.conv2.weight': 671.6881713867188, 'layer3.0.bn2.weight': 0.7466219663619995, 'layer3.0.bn2.bias': 2.457965850830078, 'layer3.0.downsample.0.weight': 97.28018188476562, 'layer3.0.downsample.1.weight': 0.8609437346458435, 'layer3.0.downsample.1.bias': 2.457965850830078, 'layer3.1.conv1.weight': 714.941162109375, 'layer3.1.bn1.weight': 0.7087836861610413, 'layer3.1.bn1.bias': 1.94098961353302, 'layer3.1.conv2.weight': 562.9638061523438, 'layer3.1.bn2.weight': 0.5239978432655334, 'layer3.1.bn2.bias': 2.963538885116577, 'layer4.0.conv1.weight': 459.28692626953125, 'layer4.0.bn1.weight': 0.3796781599521637, 'layer4.0.bn1.bias': 1.4705445766448975, 'layer4.0.conv2.weight': 348.3826904296875, 'layer4.0.bn2.weight': 0.4040968120098114, 'layer4.0.bn2.bias': 5.007317543029785, 'layer4.0.downsample.0.weight': 354.64337158203125, 'layer4.0.downsample.1.weight': 1.860112190246582, 'layer4.0.downsample.1.bias': 5.007317543029785, 'layer4.1.conv1.weight': 192.96343994140625, 'layer4.1.bn1.weight': 0.2427242547273636, 'layer4.1.bn1.bias': 2.011349678039551, 'layer4.1.conv2.weight': 244.41278076171875, 'layer4.1.bn2.weight': 0.2979035973548889, 'layer4.1.bn2.bias': 7.569357395172119, 'fc.weight': 178.7959442138672, 'fc.bias': 1.792847752571106}], 'truck': [{'conv1.weight': 117.88916015625, 'bn1.weight': 0.4461522102355957, 'bn1.bias': 1.1717267036437988, 'layer1.0.conv1.weight': 101.00700378417969, 'layer1.0.bn1.weight': 0.31190386414527893, 'layer1.0.bn1.bias': 0.7003361582756042, 'layer1.0.conv2.weight': 96.95405578613281, 'layer1.0.bn2.weight': 0.23642759025096893, 'layer1.0.bn2.bias': 0.8815951943397522, 'layer1.1.conv1.weight': 108.46786499023438, 'layer1.1.bn1.weight': 0.2286960929632187, 'layer1.1.bn1.bias': 0.5509793758392334, 'layer1.1.conv2.weight': 110.84667205810547, 'layer1.1.bn2.weight': 0.2858113944530487, 'layer1.1.bn2.bias': 0.7782564759254456, 'layer2.0.conv1.weight': 204.31634521484375, 'layer2.0.bn1.weight': 0.4195595979690552, 'layer2.0.bn1.bias': 0.8806719779968262, 'layer2.0.conv2.weight': 268.4831848144531, 'layer2.0.bn2.weight': 0.40676549077033997, 'layer2.0.bn2.bias': 1.2718119621276855, 'layer2.0.downsample.0.weight': 33.37019729614258, 'layer2.0.downsample.1.weight': 0.4810202121734619, 'layer2.0.downsample.1.bias': 1.2718119621276855, 'layer2.1.conv1.weight': 340.06353759765625, 'layer2.1.bn1.weight': 0.5968950390815735, 'layer2.1.bn1.bias': 1.1599452495574951, 'layer2.1.conv2.weight': 371.90045166015625, 'layer2.1.bn2.weight': 0.6236327886581421, 'layer2.1.bn2.bias': 1.6812983751296997, 'layer3.0.conv1.weight': 705.8883056640625, 'layer3.0.bn1.weight': 0.8137466907501221, 'layer3.0.bn1.bias': 1.5210312604904175, 'layer3.0.conv2.weight': 805.3319702148438, 'layer3.0.bn2.weight': 0.8467063307762146, 'layer3.0.bn2.bias': 2.265133857727051, 'layer3.0.downsample.0.weight': 110.03827667236328, 'layer3.0.downsample.1.weight': 0.981661856174469, 'layer3.0.downsample.1.bias': 2.265133857727051, 'layer3.1.conv1.weight': 785.4092407226562, 'layer3.1.bn1.weight': 0.7289084196090698, 'layer3.1.bn1.bias': 1.6938450336456299, 'layer3.1.conv2.weight': 717.0868530273438, 'layer3.1.bn2.weight': 0.677409827709198, 'layer3.1.bn2.bias': 2.969057321548462, 'layer4.0.conv1.weight': 605.9324951171875, 'layer4.0.bn1.weight': 0.5479252934455872, 'layer4.0.bn1.bias': 1.5864440202713013, 'layer4.0.conv2.weight': 455.5464782714844, 'layer4.0.bn2.weight': 0.5073580145835876, 'layer4.0.bn2.bias': 5.272196292877197, 'layer4.0.downsample.0.weight': 461.0652770996094, 'layer4.0.downsample.1.weight': 2.3932549953460693, 'layer4.0.downsample.1.bias': 5.272196292877197, 'layer4.1.conv1.weight': 220.4054718017578, 'layer4.1.bn1.weight': 0.2726076543331146, 'layer4.1.bn1.bias': 1.8894952535629272, 'layer4.1.conv2.weight': 303.24176025390625, 'layer4.1.bn2.weight': 0.36837127804756165, 'layer4.1.bn2.bias': 7.681856155395508, 'fc.weight': 214.8895721435547, 'fc.bias': 1.7707579135894775}]}\n"
     ]
    }
   ],
   "source": [
    "# Example: Print L1 norms for the first datapoint in the 'cat' class\n",
    "\n",
    "print(datapoint_param_l1_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter names recorded: 62\n",
      "{'conv1.weight': [93.09488677978516, 99.9708251953125, 85.234375, 95.59966278076172, 85.37320709228516, 88.54503631591797, 73.4692153930664, 101.28894805908203, 132.15042114257812, 117.88916015625], 'bn1.weight': [0.2949860095977783, 0.4723351299762726, 0.3490413427352905, 0.39669060707092285, 0.3856979012489319, 0.39345985651016235, 0.2959410846233368, 0.5114227533340454, 0.41280925273895264, 0.4461522102355957], 'bn1.bias': [0.9864556193351746, 1.4952583312988281, 1.4164389371871948, 1.1645792722702026, 1.2864941358566284, 1.2235642671585083, 1.1358470916748047, 1.526517629623413, 1.1785783767700195, 1.1717267036437988], 'layer1.0.conv1.weight': [73.61775207519531, 107.25581359863281, 80.0821762084961, 80.64580535888672, 82.10076904296875, 87.46463012695312, 90.75541687011719, 111.47354125976562, 80.61528015136719, 101.00700378417969], 'layer1.0.bn1.weight': [0.1968373954296112, 0.2875302731990814, 0.21159937977790833, 0.20568352937698364, 0.19401471316814423, 0.2536087930202484, 0.21655243635177612, 0.2629653513431549, 0.20964403450489044, 0.31190386414527893], 'layer1.0.bn1.bias': [0.6792192459106445, 0.7360710501670837, 0.6549720168113708, 0.5156785845756531, 0.7342986464500427, 0.7440999746322632, 0.7270944118499756, 0.6859208345413208, 0.655554473400116, 0.7003361582756042], 'layer1.0.conv2.weight': [80.63255310058594, 106.635009765625, 94.29121398925781, 89.06192016601562, 78.30982971191406, 85.07620239257812, 77.6774673461914, 111.07958221435547, 96.93002319335938, 96.95405578613281], 'layer1.0.bn2.weight': [0.230294868350029, 0.2743242681026459, 0.17744465172290802, 0.19745267927646637, 0.1958237588405609, 0.24667991697788239, 0.17748889327049255, 0.24031412601470947, 0.2879563271999359, 0.23642759025096893], 'layer1.0.bn2.bias': [1.0418732166290283, 1.1945751905441284, 1.1818510293960571, 0.8400050401687622, 1.015326976776123, 0.9736360907554626, 0.8877763748168945, 1.0898767709732056, 1.1380784511566162, 0.8815951943397522], 'layer1.1.conv1.weight': [87.55230712890625, 116.81861877441406, 111.04802703857422, 98.43330383300781, 94.59785461425781, 98.39053344726562, 102.85346221923828, 124.07696533203125, 101.22364044189453, 108.46786499023438], 'layer1.1.bn1.weight': [0.24405138194561005, 0.346280962228775, 0.3571348488330841, 0.30400246381759644, 0.26623111963272095, 0.28408145904541016, 0.32319191098213196, 0.3563194274902344, 0.30203723907470703, 0.2286960929632187], 'layer1.1.bn1.bias': [0.5640832781791687, 0.6329461932182312, 0.7786791324615479, 0.5628646016120911, 0.6496736407279968, 0.6165845394134521, 0.6730659604072571, 0.7135776877403259, 0.6513868570327759, 0.5509793758392334], 'layer1.1.conv2.weight': [101.27618408203125, 120.23631286621094, 101.55642700195312, 108.94694519042969, 101.46180725097656, 108.49310302734375, 102.66056060791016, 138.61349487304688, 114.11860656738281, 110.84667205810547], 'layer1.1.bn2.weight': [0.23329201340675354, 0.273947149515152, 0.2563217282295227, 0.2400389313697815, 0.2539505064487457, 0.27212807536125183, 0.3053765296936035, 0.32247981429100037, 0.23491385579109192, 0.2858113944530487], 'layer1.1.bn2.bias': [0.975649356842041, 1.0033714771270752, 1.0328853130340576, 0.8632024526596069, 1.027366042137146, 1.0037710666656494, 1.0130001306533813, 1.0393034219741821, 1.0493377447128296, 0.7782564759254456], 'layer2.0.conv1.weight': [161.82977294921875, 228.11502075195312, 173.18917846679688, 203.28802490234375, 163.9732666015625, 172.74465942382812, 173.3148193359375, 216.53274536132812, 181.39486694335938, 204.31634521484375], 'layer2.0.bn1.weight': [0.3451741635799408, 0.4892921447753906, 0.3324201703071594, 0.42713525891304016, 0.3640730381011963, 0.3686882257461548, 0.3372182846069336, 0.4624338746070862, 0.3902813792228699, 0.4195595979690552], 'layer2.0.bn1.bias': [0.840376615524292, 1.0525569915771484, 0.9079219698905945, 0.8984435796737671, 0.8564515113830566, 0.8380071520805359, 0.8005079627037048, 0.9668608903884888, 0.923330545425415, 0.8806719779968262], 'layer2.0.conv2.weight': [236.7536163330078, 301.8134765625, 245.96348571777344, 261.7263488769531, 222.55258178710938, 234.88882446289062, 232.65676879882812, 318.29730224609375, 250.51089477539062, 268.4831848144531], 'layer2.0.bn2.weight': [0.40090662240982056, 0.5059032440185547, 0.42628276348114014, 0.4782974123954773, 0.36651280522346497, 0.37570998072624207, 0.39384138584136963, 0.5625975131988525, 0.47344452142715454, 0.40676549077033997], 'layer2.0.bn2.bias': [1.394970178604126, 1.5383614301681519, 1.476858139038086, 1.2672698497772217, 1.1973106861114502, 1.272533893585205, 1.2725106477737427, 1.5152076482772827, 1.4365729093551636, 1.2718119621276855], 'layer2.0.downsample.0.weight': [28.244354248046875, 37.8609504699707, 29.555692672729492, 29.816452026367188, 25.559480667114258, 28.06658172607422, 27.900924682617188, 37.38923645019531, 30.16438865661621, 33.37019729614258], 'layer2.0.downsample.1.weight': [0.4165607988834381, 0.596854567527771, 0.4426422119140625, 0.396767258644104, 0.38019728660583496, 0.4506811499595642, 0.3702158033847809, 0.5540759563446045, 0.40324464440345764, 0.4810202121734619], 'layer2.0.downsample.1.bias': [1.394970178604126, 1.5383614301681519, 1.476858139038086, 1.2672698497772217, 1.1973106861114502, 1.272533893585205, 1.2725106477737427, 1.5152076482772827, 1.4365729093551636, 1.2718119621276855], 'layer2.1.conv1.weight': [272.8011169433594, 333.36328125, 261.4861755371094, 287.2484436035156, 255.91302490234375, 258.0105285644531, 276.11676025390625, 317.38909912109375, 264.3865661621094, 340.06353759765625], 'layer2.1.bn1.weight': [0.45924249291419983, 0.5833671689033508, 0.4411984086036682, 0.4895161986351013, 0.4460703432559967, 0.465335488319397, 0.4772889018058777, 0.5085334777832031, 0.3958047330379486, 0.5968950390815735], 'layer2.1.bn1.bias': [1.0785895586013794, 1.2102043628692627, 1.0828183889389038, 1.0191357135772705, 1.123752474784851, 0.9574342370033264, 1.0084753036499023, 1.1234428882598877, 0.9795873165130615, 1.1599452495574951], 'layer2.1.conv2.weight': [292.64459228515625, 400.0797424316406, 341.5504455566406, 372.807373046875, 300.88568115234375, 326.81329345703125, 339.1263732910156, 402.8927001953125, 315.0000915527344, 371.90045166015625], 'layer2.1.bn2.weight': [0.49057644605636597, 0.6548895835876465, 0.5885229706764221, 0.6727890968322754, 0.5612233877182007, 0.5551227927207947, 0.5632817149162292, 0.6802452206611633, 0.4741029739379883, 0.6236327886581421], 'layer2.1.bn2.bias': [1.5773905515670776, 1.9324477910995483, 1.9062206745147705, 1.9116655588150024, 1.6762733459472656, 1.7025905847549438, 1.6708259582519531, 1.8364543914794922, 1.8070629835128784, 1.6812983751296997], 'layer3.0.conv1.weight': [644.1712036132812, 774.5001220703125, 713.9357299804688, 728.1762084960938, 584.232421875, 682.968994140625, 711.990966796875, 840.246826171875, 640.3292846679688, 705.8883056640625], 'layer3.0.bn1.weight': [0.750715434551239, 0.9510712027549744, 0.8222329616546631, 0.8166561126708984, 0.5616084933280945, 0.7747889757156372, 0.8090614080429077, 0.9075337648391724, 0.7288200259208679, 0.8137466907501221], 'layer3.0.bn1.bias': [1.5666824579238892, 1.696627140045166, 1.870855689048767, 1.6757980585098267, 1.5292168855667114, 1.5560003519058228, 1.7121697664260864, 1.7497681379318237, 1.7496825456619263, 1.5210312604904175], 'layer3.0.conv2.weight': [692.2122802734375, 855.6111450195312, 803.2518920898438, 777.3492431640625, 668.2784423828125, 715.6099853515625, 755.231689453125, 870.8828735351562, 671.6881713867188, 805.3319702148438], 'layer3.0.bn2.weight': [0.6834148168563843, 0.8565371632575989, 0.9654670357704163, 0.7801032662391663, 0.6779394745826721, 0.7555106282234192, 0.8253719210624695, 0.9560470581054688, 0.7466219663619995, 0.8467063307762146], 'layer3.0.bn2.bias': [2.3756611347198486, 2.600130796432495, 2.934361696243286, 2.4775280952453613, 2.486713171005249, 2.143395185470581, 2.4415860176086426, 2.6123130321502686, 2.457965850830078, 2.265133857727051], 'layer3.0.downsample.0.weight': [96.45172119140625, 119.1539077758789, 111.8313217163086, 107.6875, 94.91064453125, 93.96656036376953, 105.17928314208984, 120.3872299194336, 97.28018188476562, 110.03827667236328], 'layer3.0.downsample.1.weight': [0.9324091672897339, 1.078373908996582, 0.9492825865745544, 1.0173931121826172, 0.8797796964645386, 0.7713707089424133, 0.9294155836105347, 1.1119636297225952, 0.8609437346458435, 0.981661856174469], 'layer3.0.downsample.1.bias': [2.3756611347198486, 2.600130796432495, 2.934361696243286, 2.4775280952453613, 2.486713171005249, 2.143395185470581, 2.4415860176086426, 2.6123130321502686, 2.457965850830078, 2.265133857727051], 'layer3.1.conv1.weight': [675.9895629882812, 830.2398071289062, 754.91748046875, 786.1414794921875, 692.2449951171875, 750.3267211914062, 760.94677734375, 876.906005859375, 714.941162109375, 785.4092407226562], 'layer3.1.bn1.weight': [0.6527437567710876, 0.7892802953720093, 0.7755401730537415, 0.7916085720062256, 0.672650158405304, 0.7821840643882751, 0.7510639429092407, 0.9016175270080566, 0.7087836861610413, 0.7289084196090698], 'layer3.1.bn1.bias': [1.726965308189392, 1.8851442337036133, 2.1319310665130615, 1.9615435600280762, 1.9815936088562012, 1.7940860986709595, 1.924941897392273, 2.020435333251953, 1.94098961353302, 1.6938450336456299], 'layer3.1.conv2.weight': [639.1650390625, 710.707275390625, 635.5409545898438, 689.0994262695312, 598.0016479492188, 617.9196166992188, 636.3115234375, 792.5587768554688, 562.9638061523438, 717.0868530273438], 'layer3.1.bn2.weight': [0.6608100533485413, 0.6995677947998047, 0.6786929368972778, 0.7191526889801025, 0.615502119064331, 0.6019865870475769, 0.6576085090637207, 0.8571063876152039, 0.5239978432655334, 0.677409827709198], 'layer3.1.bn2.bias': [3.1433873176574707, 3.083303213119507, 3.3222737312316895, 3.107457160949707, 3.115570306777954, 2.7346596717834473, 3.030473470687866, 3.3823063373565674, 2.963538885116577, 2.969057321548462], 'layer4.0.conv1.weight': [549.0866088867188, 579.0201416015625, 501.2120666503906, 577.3569946289062, 498.120849609375, 492.19268798828125, 511.66741943359375, 633.77734375, 459.28692626953125, 605.9324951171875], 'layer4.0.bn1.weight': [0.48965585231781006, 0.5040081143379211, 0.4437166452407837, 0.4960860311985016, 0.4405430555343628, 0.41620999574661255, 0.4428131580352783, 0.5723575949668884, 0.3796781599521637, 0.5479252934455872], 'layer4.0.bn1.bias': [1.6666512489318848, 1.5384541749954224, 1.583782434463501, 1.5971616506576538, 1.5980018377304077, 1.329969048500061, 1.4671978950500488, 1.6629306077957153, 1.4705445766448975, 1.5864440202713013], 'layer4.0.conv2.weight': [378.73016357421875, 414.5741271972656, 383.8764953613281, 430.39776611328125, 381.7982482910156, 390.2791442871094, 402.6506042480469, 443.8070068359375, 348.3826904296875, 455.5464782714844], 'layer4.0.bn2.weight': [0.43593457341194153, 0.4870275557041168, 0.444568008184433, 0.4882577955722809, 0.4505079984664917, 0.45175406336784363, 0.4761093854904175, 0.5257713198661804, 0.4040968120098114, 0.5073580145835876], 'layer4.0.bn2.bias': [5.144650459289551, 4.879399299621582, 5.353424072265625, 5.228686332702637, 5.357222080230713, 4.6814351081848145, 5.045175075531006, 5.1214280128479, 5.007317543029785, 5.272196292877197], 'layer4.0.downsample.0.weight': [379.87811279296875, 416.99652099609375, 383.05914306640625, 429.0986328125, 376.7118225097656, 390.56951904296875, 398.7559509277344, 441.22857666015625, 354.64337158203125, 461.0652770996094], 'layer4.0.downsample.1.weight': [1.9606181383132935, 2.0095043182373047, 1.9045666456222534, 2.1700069904327393, 1.8889214992523193, 1.9671248197555542, 1.9885848760604858, 2.1717820167541504, 1.860112190246582, 2.3932549953460693], 'layer4.0.downsample.1.bias': [5.144650459289551, 4.879399299621582, 5.353424072265625, 5.228686332702637, 5.357222080230713, 4.6814351081848145, 5.045175075531006, 5.1214280128479, 5.007317543029785, 5.272196292877197], 'layer4.1.conv1.weight': [199.3954620361328, 208.87474060058594, 182.63772583007812, 213.14773559570312, 193.76162719726562, 217.17608642578125, 204.1578369140625, 213.7399139404297, 192.96343994140625, 220.4054718017578], 'layer4.1.bn1.weight': [0.23516780138015747, 0.26245740056037903, 0.23167137801647186, 0.27741068601608276, 0.24613001942634583, 0.27001047134399414, 0.2543502449989319, 0.26848268508911133, 0.2427242547273636, 0.2726076543331146], 'layer4.1.bn1.bias': [1.986002802848816, 1.833617091178894, 1.9205598831176758, 1.9621275663375854, 2.0894699096679688, 1.962148666381836, 1.967612624168396, 1.8664278984069824, 2.011349678039551, 1.8894952535629272], 'layer4.1.conv2.weight': [258.4543151855469, 285.548583984375, 257.8779296875, 283.60595703125, 250.3956756591797, 265.9263000488281, 268.95306396484375, 295.4501953125, 244.41278076171875, 303.24176025390625], 'layer4.1.bn2.weight': [0.33564841747283936, 0.34504687786102295, 0.3270263671875, 0.3583764433860779, 0.3031448721885681, 0.32071807980537415, 0.32454267144203186, 0.3624517321586609, 0.2979035973548889, 0.36837127804756165], 'layer4.1.bn2.bias': [7.670624732971191, 7.443964958190918, 8.019668579101562, 7.68412446975708, 7.95579719543457, 7.14168643951416, 7.698010444641113, 7.629717826843262, 7.569357395172119, 7.681856155395508], 'fc.weight': [188.521240234375, 211.8446044921875, 179.51783752441406, 199.62744140625, 178.76783752441406, 199.6325225830078, 194.2245635986328, 221.17587280273438, 178.7959442138672, 214.8895721435547], 'fc.bias': [1.8070822954177856, 1.7869027853012085, 1.815758228302002, 1.7641897201538086, 1.8497653007507324, 1.730948805809021, 1.7975438833236694, 1.8527631759643555, 1.792847752571106, 1.7707579135894775]}\n"
     ]
    }
   ],
   "source": [
    "# Make dictionary to hold parameter importance across all classes\n",
    "\n",
    "# Make list of all parameters\n",
    "parameter_names = list(next(iter(datapoint_param_l1_norms.values()))[0].keys())\n",
    "print(\"\\nParameter names recorded:\", len(parameter_names))\n",
    "\n",
    "parameter_values = {param_name: [] for param_name in parameter_names}\n",
    "for class_name, norms_list in datapoint_param_l1_norms.items():\n",
    "    for param_name in parameter_names:\n",
    "        parameter_values[param_name].extend([norms[param_name] for norms in norms_list])\n",
    "\n",
    "\n",
    "print(parameter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.986002802848816,\n",
       " 1.833617091178894,\n",
       " 1.9205598831176758,\n",
       " 1.9621275663375854,\n",
       " 2.0894699096679688,\n",
       " 1.962148666381836,\n",
       " 1.967612624168396,\n",
       " 1.8664278984069824,\n",
       " 2.011349678039551,\n",
       " 1.8894952535629272]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example: Access importance values for a specific parameter\n",
    "\n",
    "parameter_values['layer4.1.bn1.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpter functions to get max and min info from a list\n",
    "\n",
    "def get_max_info(list):\n",
    "    max_value = 0\n",
    "    max_index = -1\n",
    "    for i in range(len(list)):\n",
    "        if list[i] > max_value:\n",
    "            max_value = list[i]\n",
    "            max_index = i\n",
    "    return max_value\n",
    "\n",
    "def get_min_info(list):\n",
    "    min_value = float('inf')\n",
    "    min_index = -1\n",
    "    for i in range(len(list)):\n",
    "        if list[i] < min_value:\n",
    "            min_value = list[i]\n",
    "            min_index = i\n",
    "    return min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_index_params example (first 5 parameters):\n",
      "  conv1.weight: Max Value = 118.935379\n",
      "  bn1.weight: Max Value = 0.460280\n",
      "  bn1.bias: Max Value = 1.373866\n",
      "  layer1.0.conv1.weight: Max Value = 100.326187\n",
      "  layer1.0.bn1.weight: Max Value = 0.280713\n",
      "  layer1.0.bn1.bias: Max Value = 0.669690\n",
      "  layer1.0.conv2.weight: Max Value = 99.971624\n",
      "  layer1.0.bn2.weight: Max Value = 0.259161\n",
      "  layer1.0.bn2.bias: Max Value = 1.075118\n",
      "  layer1.1.conv1.weight: Max Value = 111.669269\n",
      "  layer1.1.bn1.weight: Max Value = 0.321421\n",
      "  layer1.1.bn1.bias: Max Value = 0.700811\n",
      "  layer1.1.conv2.weight: Max Value = 124.752145\n",
      "  layer1.1.bn2.weight: Max Value = 0.290232\n",
      "  layer1.1.bn2.bias: Max Value = 0.944404\n",
      "  layer2.0.conv1.weight: Max Value = 205.303519\n",
      "  layer2.0.bn1.weight: Max Value = 0.440363\n",
      "  layer2.0.bn1.bias: Max Value = 0.947301\n",
      "  layer2.0.conv2.weight: Max Value = 286.467572\n",
      "  layer2.0.bn2.weight: Max Value = 0.506338\n",
      "  layer2.0.bn2.bias: Max Value = 1.384525\n",
      "  layer2.0.downsample.0.weight: Max Value = 34.074855\n",
      "  layer2.0.downsample.1.weight: Max Value = 0.537169\n",
      "  layer2.0.downsample.1.bias: Max Value = 1.384525\n",
      "  layer2.1.conv1.weight: Max Value = 306.057184\n",
      "  layer2.1.bn1.weight: Max Value = 0.537206\n",
      "  layer2.1.bn1.bias: Max Value = 1.089184\n",
      "  layer2.1.conv2.weight: Max Value = 362.603430\n",
      "  layer2.1.bn2.weight: Max Value = 0.612221\n",
      "  layer2.1.bn2.bias: Max Value = 1.739203\n",
      "  layer3.0.conv1.weight: Max Value = 756.222144\n",
      "  layer3.0.bn1.weight: Max Value = 0.855964\n",
      "  layer3.0.bn1.bias: Max Value = 1.683770\n",
      "  layer3.0.conv2.weight: Max Value = 783.794586\n",
      "  layer3.0.bn2.weight: Max Value = 0.868920\n",
      "  layer3.0.bn2.bias: Max Value = 2.640926\n",
      "  layer3.0.downsample.0.weight: Max Value = 108.348507\n",
      "  layer3.0.downsample.1.weight: Max Value = 1.000767\n",
      "  layer3.0.downsample.1.bias: Max Value = 2.640926\n",
      "  layer3.1.conv1.weight: Max Value = 789.215405\n",
      "  layer3.1.bn1.weight: Max Value = 0.811456\n",
      "  layer3.1.bn1.bias: Max Value = 1.918738\n",
      "  layer3.1.conv2.weight: Max Value = 713.302899\n",
      "  layer3.1.bn2.weight: Max Value = 0.771396\n",
      "  layer3.1.bn2.bias: Max Value = 3.044076\n",
      "  layer4.0.conv1.weight: Max Value = 570.399609\n",
      "  layer4.0.bn1.weight: Max Value = 0.515122\n",
      "  layer4.0.bn1.bias: Max Value = 1.499986\n",
      "  layer4.0.conv2.weight: Max Value = 409.991830\n",
      "  layer4.0.bn2.weight: Max Value = 0.473194\n",
      "  layer4.0.bn2.bias: Max Value = 4.821500\n",
      "  layer4.0.downsample.0.weight: Max Value = 414.958749\n",
      "  layer4.0.downsample.1.weight: Max Value = 2.153929\n",
      "  layer4.0.downsample.1.bias: Max Value = 4.821500\n",
      "  layer4.1.conv1.weight: Max Value = 198.364925\n",
      "  layer4.1.bn1.weight: Max Value = 0.249670\n",
      "  layer4.1.bn1.bias: Max Value = 1.880523\n",
      "  layer4.1.conv2.weight: Max Value = 272.917584\n",
      "  layer4.1.bn2.weight: Max Value = 0.331534\n",
      "  layer4.1.bn2.bias: Max Value = 7.217702\n",
      "  fc.weight: Max Value = 199.058286\n",
      "  fc.bias: Max Value = 1.667487\n"
     ]
    }
   ],
   "source": [
    "# Get max index and value for each parameter\n",
    "\n",
    "parameter_threshold = {}\n",
    "for param_name, norms in parameter_values.items():\n",
    "\n",
    "    parameter_threshold[param_name] = get_max_info(norms) * .9\n",
    "\n",
    "print(\"max_index_params example (first 5 parameters):\")\n",
    "for i, (param_name,  max_value) in enumerate(parameter_threshold.items()):\n",
    "    print(f\"  {param_name}: Max Value = {max_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "47\n",
      "22\n",
      "22\n",
      "11\n",
      "7\n",
      "14\n",
      "55\n",
      "14\n",
      "28\n",
      "{'airplane': ['layer1.0.bn1.bias', 'layer1.1.bn2.bias', 'layer2.0.bn2.bias', 'layer2.0.downsample.1.bias', 'layer3.1.bn2.bias', 'layer4.0.bn1.bias', 'layer4.0.bn2.bias', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'fc.bias'], 'automobile': ['bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight', 'layer2.0.bn2.bias', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.1.conv1.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'fc.weight', 'fc.bias'], 'bird': ['bn1.bias', 'layer1.0.bn2.bias', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn2.bias', 'layer2.0.bn2.bias', 'layer2.0.downsample.1.bias', 'layer2.1.bn2.bias', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.bias', 'layer3.1.bn1.bias', 'layer3.1.bn2.bias', 'layer4.0.bn1.bias', 'layer4.0.bn2.bias', 'layer4.0.downsample.1.bias', 'layer4.1.bn1.bias', 'layer4.1.bn2.bias', 'fc.bias'], 'cat': ['layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.downsample.1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'fc.weight', 'fc.bias'], 'deer': ['layer1.0.bn1.bias', 'layer1.1.bn2.bias', 'layer2.1.bn1.bias', 'layer3.1.bn1.bias', 'layer3.1.bn2.bias', 'layer4.0.bn1.bias', 'layer4.0.bn2.bias', 'layer4.0.downsample.1.bias', 'layer4.1.bn1.bias', 'layer4.1.bn2.bias', 'fc.bias'], 'dog': ['layer1.0.bn1.bias', 'layer1.1.bn2.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'fc.weight', 'fc.bias'], 'frog': ['layer1.0.bn1.bias', 'layer1.1.bn1.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer3.0.bn1.bias', 'layer3.1.bn1.bias', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn2.bias', 'fc.bias'], 'horse': ['bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.1.conv1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'fc.weight', 'fc.bias'], 'ship': ['conv1.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.bn2.bias', 'layer2.0.bn2.bias', 'layer2.0.downsample.1.bias', 'layer2.1.bn2.bias', 'layer3.0.bn1.bias', 'layer3.1.bn1.bias', 'layer4.0.bn2.bias', 'layer4.0.downsample.1.bias', 'layer4.1.bn1.bias', 'layer4.1.bn2.bias', 'fc.bias'], 'truck': ['layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer3.0.conv2.weight', 'layer3.0.downsample.0.weight', 'layer3.1.conv2.weight', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'fc.weight', 'fc.bias']}\n"
     ]
    }
   ],
   "source": [
    "# Create masks for each parameter based on epsilon thresholding\n",
    "\n",
    "\n",
    "parameter_masks_per_class = {class_name: [] for class_name in class_names}\n",
    "\n",
    "for class_name, norms_list in datapoint_param_l1_norms.items():\n",
    "    class_masks = []\n",
    "    \n",
    "    for (param_name, param_value) in norms_list[0].items():\n",
    "        if param_value >= parameter_threshold[param_name]:\n",
    "            class_masks.append(param_name)\n",
    "\n",
    "    parameter_masks_per_class[class_name] = class_masks\n",
    "   \n",
    "print(parameter_masks_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate the ResNet18 model\n",
    "unlearn_model = resnet18(pretrained=False)\n",
    "\n",
    "# Modify the final fully connected layer for CIFAR10 (10 classes)\n",
    "num_ftrs = model.fc.in_features\n",
    "unlearn_model.fc = nn.Linear(num_ftrs, 10)\n",
    "unlearn_model.load_state_dict(torch.load('best_cifar10_resnet18.pth'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "unlearn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): Identity()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_batchnorm(model):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.BatchNorm2d):\n",
    "            setattr(model, name, torch.nn.Identity())\n",
    "        else:\n",
    "            remove_batchnorm(module)\n",
    "\n",
    "remove_batchnorm(unlearn_model)\n",
    "unlearn_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [2/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [3/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [4/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [5/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [6/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [7/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [8/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [9/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Epoch [10/10], Loss: nan\n",
      "Accuracy: 10.00%\n",
      "Gradient ascent/descent completed for the unlearning dataset.\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Set model to evaluation mode\n",
    "\n",
    "num_epoch_unlearn = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epoch in range(num_epoch_unlearn):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(unlearn_loader):\n",
    "\n",
    "        # Move inputs and labels to the appropriate device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print(inputs, inputs.shape)\n",
    "\n",
    "        # Perform a forward pass\n",
    "        outputs = unlearn_model(inputs)\n",
    "\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model's weights\n",
    "        with torch.no_grad():\n",
    "            for param in unlearn_model.parameters():\n",
    "                if (labels == 1).any():  # Gradient ascent for class 1\n",
    "                    param += learning_rate * param.grad\n",
    "                else:  # Gradient descent for other classes\n",
    "                    param -= learning_rate * param.grad\n",
    "\n",
    "        # Zero the gradients after the update\n",
    "        unlearn_model.zero_grad()\n",
    "    print(f'Epoch [{epoch + 1}/{num_epoch_unlearn}], Loss: {running_loss}')\n",
    "    print(f\"Accuracy: {compute_accuracy(unlearn_model, test_loader)[0]:.2f}%\")\n",
    "\n",
    "print(\"Gradient ascent/descent completed for the unlearning dataset.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 10.00 %\n",
      "Class-wise accuracies:\n",
      "Class 0: 100.00 %\n",
      "Class 1: 0.00 %\n",
      "Class 2: 0.00 %\n",
      "Class 3: 0.00 %\n",
      "Class 4: 0.00 %\n",
      "Class 5: 0.00 %\n",
      "Class 6: 0.00 %\n",
      "Class 7: 0.00 %\n",
      "Class 8: 0.00 %\n",
      "Class 9: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy, class_accuracies = compute_accuracy(unlearn_model, test_loader)\n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f} %')\n",
    "print('Class-wise accuracies:')\n",
    "for i in range(10):\n",
    "    print(f'Class {i}: {class_accuracies[i]:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 10.37 %\n",
      "Class-wise accuracies:\n",
      "Class 0: 0.00 %\n",
      "Class 1: 0.10 %\n",
      "Class 2: 0.00 %\n",
      "Class 3: 11.70 %\n",
      "Class 4: 0.00 %\n",
      "Class 5: 90.90 %\n",
      "Class 6: 0.00 %\n",
      "Class 7: 0.00 %\n",
      "Class 8: 0.00 %\n",
      "Class 9: 1.00 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "accuracy, class_accuracies = compute_accuracy(model, test_loader)\n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f} %')\n",
    "print('Class-wise accuracies:')\n",
    "for i in range(10):\n",
    "    print(f'Class {i}: {class_accuracies[i]:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
